{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37529d65-4ca2-4e05-985d-9472f080872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 5.6G Nov 14 11:37 /tmp/lhcf-cnn/combined_data.h5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "DATA_DIR=/tmp/lhcf-cnn\n",
    "\n",
    "if [ ! -d $DATA_DIR ]; then\n",
    "  mkdir -p $DATA_DIR\n",
    "fi\n",
    "\n",
    "if [ ! -f $DATA_DIR/combined_data.h5 ]; then\n",
    "  wget https://minio.131.154.99.37.myip.cloud.infn.it/hackathon-data/lhcf-cnn/combined_data.h5 -O $DATA_DIR/combined_data.h5 &> .log\n",
    "fi\n",
    "\n",
    "ls -lrth $DATA_DIR/combined_data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be18833-f200-405a-97d9-deb8f20a1759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 00:27:59.404838: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-15 00:28:00.736181: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-15 00:28:00.736231: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-15 00:28:00.743018: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 00:28:01.320883: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7987f937-9a2f-4e9c-b9a8-b95e6b387ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/tmp/lhcf-cnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37653dc3-5eb2-4e44-8ea2-3e0f5715a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare un esempio TFRecord\n",
    "def create_tfrecord_example(posdE_01xy, posdE_23x, posdE_23y, dE, label):\n",
    "    features = {\n",
    "        \"posdE_01xy\": tf.train.Feature(float_list=tf.train.FloatList(value=posdE_01xy.reshape(-1))),\n",
    "        \"posdE_23x\": tf.train.Feature(float_list=tf.train.FloatList(value=posdE_23x.reshape(-1))),\n",
    "        \"posdE_23y\": tf.train.Feature(float_list=tf.train.FloatList(value=posdE_23y.reshape(-1))),\n",
    "        \"dE\": tf.train.Feature(float_list=tf.train.FloatList(value=dE.reshape(-1))),\n",
    "        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "\n",
    "# Funzione per scrivere un batch di esempi in un file TFRecord con aggiornamento della barra di avanzamento\n",
    "def write_tfrecord_batch(h5_file_path, indices, tfrecord_file_path, progress_queue):\n",
    "    with h5py.File(h5_file_path, \"r\") as f, tf.io.TFRecordWriter(tfrecord_file_path) as writer:\n",
    "        for i in indices:\n",
    "            posdE_01xy = f[\"posdE_01xy\"][i].astype(\"float32\")\n",
    "            posdE_23x = f[\"posdE_23x\"][i].astype(\"float32\")\n",
    "            posdE_23y = f[\"posdE_23y\"][i].astype(\"float32\")\n",
    "            dE = f[\"dE\"][i, :, 0].astype(\"float32\")  # Rimuove la dimensione extra\n",
    "            label = int(f[\"ID\"][i])\n",
    "            \n",
    "            example = create_tfrecord_example(posdE_01xy, posdE_23x, posdE_23y, dE, label)\n",
    "            writer.write(example.SerializeToString())\n",
    "            progress_queue.put(1)  # Aggiorna la barra di avanzamento\n",
    "\n",
    "\n",
    "# Funzione per mostrare lo stato di avanzamento\n",
    "def progress_listener(total_samples, progress_queue):\n",
    "    with tqdm(total=total_samples, desc=\"Conversione in TFRecord\") as pbar:\n",
    "        for _ in range(total_samples):\n",
    "            progress_queue.get()\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "# Funzione principale per dividere il dataset e scrivere in parallelo con la barra di avanzamento\n",
    "def split_and_parallel_write(h5_file_path, train_tfrecord_path, val_tfrecord_path, train_ratio=0.8, num_processes=4):\n",
    "    with h5py.File(h5_file_path, \"r\") as f:\n",
    "        n_samples = f[\"ID\"].shape[0]\n",
    "        indices = np.arange(n_samples)\n",
    "        train_indices, val_indices = train_test_split(indices, test_size=1 - train_ratio, random_state=42, shuffle=True)\n",
    "\n",
    "    # Suddividi gli indici in batch per la parallelizzazione\n",
    "    train_batches = np.array_split(train_indices, num_processes)\n",
    "    val_batches = np.array_split(val_indices, num_processes)\n",
    "\n",
    "    # Gestore per la barra di avanzamento con multiprocessing\n",
    "    manager = Manager()\n",
    "    progress_queue = manager.Queue()\n",
    "\n",
    "    # Avvia il processo della barra di avanzamento\n",
    "    total_samples = len(train_indices) + len(val_indices)\n",
    "    progress_process = Pool(1, progress_listener, (total_samples, progress_queue))\n",
    "\n",
    "    # Scrittura parallela dei file TFRecord\n",
    "    with Pool(num_processes) as pool:\n",
    "        pool.starmap(write_tfrecord_batch, [(h5_file_path, batch, f\"{train_tfrecord_path}_part{i}\", progress_queue) for i, batch in enumerate(train_batches)])\n",
    "        pool.starmap(write_tfrecord_batch, [(h5_file_path, batch, f\"{val_tfrecord_path}_part{i}\", progress_queue) for i, batch in enumerate(val_batches)])\n",
    "\n",
    "    # Termina il processo della barra di avanzamento\n",
    "    progress_process.close()\n",
    "    progress_process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf207197-e98f-4451-8b78-4764e7d77adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conversione in TFRecord: 100%|██████████| 10000/10000 [03:25<00:00, 48.64it/s]\n"
     ]
    }
   ],
   "source": [
    "src_fname = f\"{PATH}/combined_data.h5\"\n",
    "exp_dirname = f\"{PATH}/Train_and_Validation\"\n",
    "\n",
    "if not os.path.exists(exp_dirname):\n",
    "    os.makedirs(exp_dirname)\n",
    "else:\n",
    "    shutil.rmtree(exp_dirname)\n",
    "    os.makedirs(exp_dirname)\n",
    "\n",
    "# Esegui la conversione usando più processi con barra di avanzamento\n",
    "split_and_parallel_write(src_fname, f\"{exp_dirname}/train.tfrecord\", f\"{exp_dirname}/validation.tfrecord\", num_processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9deabb18-ff84-4a10-97bd-5d1596764e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 00:31:41.520983: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.648974: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.649265: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.653472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.653705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.653889: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.770181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.770423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.770611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-11-15 00:31:41.770783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14940 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "Concatenazione /tmp/lhcf-cnn/train.tfrecord: 100%|██████████| 8000/8000 [00:13<00:00, 590.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File TFRecord concatenato salvato: /tmp/lhcf-cnn/train.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Concatenazione /tmp/lhcf-cnn/validation.tfrecord: 100%|██████████| 2000/2000 [00:03<00:00, 645.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File TFRecord concatenato salvato: /tmp/lhcf-cnn/validation.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Funzione per concatenare i file TFRecord con una barra di avanzamento\n",
    "def concatenate_tfrecords(input_files, output_file):\n",
    "    total_records = sum(1 for input_file in input_files for _ in tf.data.TFRecordDataset(input_file))\n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_file) as writer:\n",
    "        with tqdm(total=total_records, desc=f\"Concatenazione {output_file}\") as pbar:\n",
    "            for input_file in input_files:\n",
    "                for record in tf.data.TFRecordDataset(input_file):\n",
    "                    writer.write(record.numpy())\n",
    "                    pbar.update(1)\n",
    "    print(f\"File TFRecord concatenato salvato: {output_file}\")\n",
    "\n",
    "# Ottieni la lista dei file TFRecord di train e validation\n",
    "train_files = sorted([os.path.join(exp_dirname, f) for f in os.listdir(exp_dirname) if f.startswith(\"train.tfrecord_part\")])\n",
    "validation_files = sorted([os.path.join(exp_dirname, f) for f in os.listdir(exp_dirname) if f.startswith(\"validation.tfrecord_part\")])\n",
    "\n",
    "# Concatena i file in un singolo TFRecord per train e validation con la barra di avanzamento\n",
    "concatenate_tfrecords(train_files, f\"{PATH}/train.tfrecord\")\n",
    "concatenate_tfrecords(validation_files, f\"{PATH}/validation.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b3eae19-7a29-4d18-89e5-d666871e0e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 17G\n",
      "-rw-r--r-- 1 root root 5.6G Nov 14 11:37 combined_data.h5\n",
      "drwxr-xr-x 2 root root 4.0K Nov 15 00:31 \u001b[0m\u001b[01;34mTrain_and_Validation\u001b[0m/\n",
      "-rw-r--r-- 1 root root 8.9G Nov 15 00:32 train.tfrecord\n",
      "-rw-r--r-- 1 root root 2.3G Nov 15 00:32 validation.tfrecord\n"
     ]
    }
   ],
   "source": [
    "ls -lrth /tmp/lhcf-cnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-k2",
   "language": "python",
   "name": "cnn-k2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
