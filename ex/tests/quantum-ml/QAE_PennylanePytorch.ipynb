{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "TaRKoXj3bKyl",
   "metadata": {
    "id": "TaRKoXj3bKyl"
   },
   "source": [
    "# A Quantum Auto-Encoder based on Parametric Quantum Circuit for anomaly detection of MNIST images\n",
    "## Tutorial - Hands-on ##\n",
    "\n",
    "**Version:** V3.1 <p>\n",
    "**Authors:** Stefano Giagu <stefano.giagu@uniroma1.it>\n",
    "\n",
    "\n",
    "**Scope:**: learn how to design a simple variational PQC and train it for a anomaly detection task using the [pennylane](https://pennylane.ai/) platform with [pytorch](https://pytorch.org/) backend\n",
    "\n",
    "**Libraries:** numpy, matplotlib, pennylane, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_O18ytQZbcFh",
   "metadata": {
    "id": "_O18ytQZbcFh"
   },
   "outputs": [],
   "source": [
    "# only needed on google colab\n",
    "#!pip install pennylane-lightning-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qvExxnOQbct4",
   "metadata": {
    "id": "qvExxnOQbct4"
   },
   "outputs": [],
   "source": [
    "# import needed libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "print('Torch version: ', torch.__version__)\n",
    "print('Pennylane version: ', qml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bPDAn3Ydbc1-",
   "metadata": {
    "id": "bPDAn3Ydbc1-"
   },
   "outputs": [],
   "source": [
    "# check if GPU is available\n",
    "# Note: the example can also be run on CPU w/o problems\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  print('Number of available GPUs: ',torch.cuda.device_count())\n",
    "  for i in range(0,torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))\n",
    "  !nvidia-smi\n",
    "else:\n",
    "  print('No GPU available')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7045a3-4fba-4c69-9a18-4202349c808b",
   "metadata": {
    "id": "1a7045a3-4fba-4c69-9a18-4202349c808b",
    "outputId": "6612bc11-3fa3-459f-bd29-55de5fbaa5e9"
   },
   "outputs": [],
   "source": [
    "# check Pennylane software stack\n",
    "qml.about()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104259f7-1b66-4f46-922b-116875245170",
   "metadata": {
    "id": "104259f7-1b66-4f46-922b-116875245170",
    "outputId": "9273b711-d206-4ef1-aa40-9af2533e44ec"
   },
   "outputs": [],
   "source": [
    "# download datasets\n",
    "# this a preprocessed dataset with MNIST 0 and 1 pixels, dowinsized to 8x8 pixels and properly normalized in [0,1]\n",
    "\n",
    "# normal data:    MNIST digit 0\n",
    "# anomalous data: MNIST digit 1\n",
    "\n",
    "!wget http://giagu.web.cern.ch/giagu/CERN/standard_data.npy\n",
    "!wget http://giagu.web.cern.ch/giagu/CERN/anomalous_data.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d158cb6-8f06-47d6-8ebc-057cff33c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "normal_data_np = np.load(\"standard_data.npy\")\n",
    "anomalous_data_np = np.load(\"anomalous_data.npy\")\n",
    "print(normal_data_np.shape)\n",
    "print(anomalous_data_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b7c603-7d84-4207-9714-142dead431e9",
   "metadata": {
    "id": "d3b7c603-7d84-4207-9714-142dead431e9",
    "outputId": "27d5dd0c-256e-4c6e-ce84-f6cb61667928"
   },
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "\n",
    "# Plot the images\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(4, 2))\n",
    "\n",
    "ax1.imshow(np.reshape(normal_data_np[0], (8,8)), cmap=\"gray\")\n",
    "ax1.set_title('normal sample')\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(np.reshape(anomalous_data_np[4], (8,8)), cmap=\"gray\")\n",
    "ax2.set_title('anomalous sample')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JYCevFthcwQJ",
   "metadata": {
    "id": "JYCevFthcwQJ"
   },
   "outputs": [],
   "source": [
    "# Define train set size, the rest will be used for test\n",
    "train_size = 5000\n",
    "\n",
    "train_set = torch.tensor(normal_data_np[0:train_size])\n",
    "normal_data_test = torch.tensor(normal_data_np[train_size:])\n",
    "anomalous_data_test = torch.tensor(anomalous_data_np)\n",
    "\n",
    "print(\"Len train set: \", len(train_set))\n",
    "print(\"Len test set: \", len(normal_data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tiG_0s5ZfPa0",
   "metadata": {
    "id": "tiG_0s5ZfPa0"
   },
   "source": [
    "**QAE architecture:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XHRzRtOjeeRR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "XHRzRtOjeeRR",
    "outputId": "ac0c5830-e480-474d-cc09-5b977c5f7fa6"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('http://giagu.web.cern.ch/giagu/CERN/QAE.png', width=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cee534-ecbb-47b6-bc48-f748b4921e4d",
   "metadata": {
    "id": "57cee534-ecbb-47b6-bc48-f748b4921e4d"
   },
   "outputs": [],
   "source": [
    "# Define a quantum device (eg the number of qubits in the circuit)\n",
    "\n",
    "NUM_QUBITS = 6 # we need 6 quibit to encode 64 pixels (8x8=64=2^6)\n",
    "\n",
    "# define the quantum device:\n",
    "dev = qml.device(\"default.qubit\", wires=NUM_QUBITS) #\"default.qubit\" is the default pennylane differentiable quantum device simulator that is capable of backprop derivatives\n",
    "\n",
    "# definition of the quantum parametric circuit for the encoder architecture\n",
    "# the circuit ansatz is made by n_layers of the same unitary block made of a 3 parametric rotations gates(along X, Y and Z) in the block sphere for each qubit, folloeed by a ladder of CNOT\n",
    "# gates to entangle the qubits, the final rotation applys only on some of the qubits that are the one that will be discarded (compressed)\n",
    "\n",
    "\n",
    "# helper function defining the quantum circuit for the encoder architecture\n",
    "def encoder_architecture(params, n_layers, n_qubits, q_compression):\n",
    "  index = 0\n",
    "  for i in range(n_layers):\n",
    "\n",
    "      # Rotation layer\n",
    "      for j in range(n_qubits):\n",
    "          qml.RX(params[index], wires=j)\n",
    "          qml.RY(params[index + 1], wires=j)\n",
    "          qml.RZ(params[index + 2], wires=j)\n",
    "          index += 3\n",
    "\n",
    "      # Entangling layer\n",
    "      for j in range(n_qubits):\n",
    "          qml.CNOT(wires=[j, (j + 1) % n_qubits])\n",
    "\n",
    "  # Final rotations on the discarded (compressed) qubits\n",
    "  for j in range(q_compression):\n",
    "      qml.RX(params[index], wires=j)\n",
    "      qml.RY(params[index + 1], wires=j)\n",
    "      qml.RZ(params[index + 2], wires=j)\n",
    "      index += 3\n",
    "\n",
    "# Quantum encoder pipeline\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def encoder(params, state, return_state=False, n_layers = 3, n_qubits = 6, q_compression = 3):\n",
    "\n",
    "    # Prepare initial state (ok in simulation, allows to skip quantum encoding of the classical data,\n",
    "    # requires the input to be pre-normalized as a quantum state)\n",
    "    qml.QubitStateVector(state, wires=range(n_qubits))\n",
    "\n",
    "    # Real quantum encoding (using amplitude encoding). If you want to use it comment previous line and uncomment this ...\n",
    "    #qml.AmplitudeEmbedding(features=state, wires=range(n_qubits))\n",
    "\n",
    "    # Quantum circuit\n",
    "    encoder_architecture(params, n_layers, n_qubits, q_compression)\n",
    "\n",
    "    if return_state:\n",
    "      return qml.state()\n",
    "\n",
    "    # Return the Z expectation values for the compressed qubits\n",
    "    # NOTE: we minimize this values that are 1: |0> or -1: |1>. So minimizing implies to force the qubit to be |1>\n",
    "    return [qml.expval(qml.PauliZ(wires=i)) for i in range(q_compression)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1854d7-0441-4ea9-a449-4fb71ec1838f",
   "metadata": {
    "id": "0f1854d7-0441-4ea9-a449-4fb71ec1838f"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters of the autoencoder\n",
    "n_layers = 4\n",
    "n_qubits = 6\n",
    "q_compression = 3\n",
    "\n",
    "# Initialize parameters\n",
    "n_params = (n_layers * n_qubits + q_compression) * 3\n",
    "params = Variable(torch.normal( mean=0. , std=0.1, size=(n_params,)), requires_grad=True)\n",
    "\n",
    "# Set the state to the first event of the training set\n",
    "state = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736831f1-55a1-4d2c-9e8f-f6cfff3c0200",
   "metadata": {
    "id": "736831f1-55a1-4d2c-9e8f-f6cfff3c0200",
    "outputId": "305389b2-e8d4-4a59-9c7a-0ebc55ef2e25"
   },
   "outputs": [],
   "source": [
    "# visualize the encoder\n",
    "\n",
    "qml.drawer.use_style(\"black_white\")\n",
    "fig, ax = qml.draw_mpl(encoder)(params, state, False, n_layers, n_qubits, q_compression)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e04e9c-01f0-4b26-86cf-15b3b0f04e08",
   "metadata": {
    "id": "28e04e9c-01f0-4b26-86cf-15b3b0f04e08",
    "outputId": "afe36e1c-4638-424f-dc6c-0753dddb39a1"
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "epochs = 2\n",
    "batch_size = 64\n",
    "steps_per_epoch = int(train_size/batch_size)\n",
    "optimizer = torch.optim.Adam([params], lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1 , gamma=0.7)\n",
    "\n",
    "# dataloader\n",
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "loss_history = []\n",
    "params_history = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "  tot_loss = 0.\n",
    "  for batch in data_loader:\n",
    "    optimizer.zero_grad()\n",
    "    batch = batch.type(torch.float).to(device='cuda:0')\n",
    "    expvals = encoder(params, batch, False, n_layers, n_qubits, q_compression)\n",
    "    loss = expvals[0].mean() + expvals[1].mean() + expvals[2].mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    tot_loss += loss.cpu().detach().numpy()\n",
    "  loss_history.append(tot_loss/steps_per_epoch)\n",
    "  params_history.append(params)\n",
    "  scheduler.step()\n",
    "  print(\"Epoch {}: avg_loss = {}\".format(epoch+1, tot_loss/steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c897616-5e60-40d9-8c44-6f0608c4ffd3",
   "metadata": {
    "id": "1c897616-5e60-40d9-8c44-6f0608c4ffd3",
    "outputId": "86d739df-13c2-4e21-bca2-b14244954486"
   },
   "outputs": [],
   "source": [
    "# Evaluation of performance on test data\n",
    "\n",
    "test_set_size = len(normal_data_test)\n",
    "print(\"Test set size: \", test_set_size)\n",
    "\n",
    "normal_data_loader = torch.utils.data.DataLoader(normal_data_test, batch_size=256, shuffle=False, drop_last=False)\n",
    "anomalous_data_loader = torch.utils.data.DataLoader(anomalous_data_test[0:len(normal_data_test)], batch_size=256, shuffle=False, drop_last=False)\n",
    "loss_s = np.asarray([])\n",
    "loss_a = np.asarray([])\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Standard data\n",
    "    for batch in normal_data_loader:\n",
    "      batch = batch.type(torch.float).to(device='cuda:0')\n",
    "      expvals = encoder(params, batch, False, n_layers, n_qubits, q_compression)\n",
    "      loss = expvals[0].cpu().numpy() + expvals[1].cpu().numpy() + expvals[2].cpu().numpy()\n",
    "      loss_s = np.concatenate([loss_s,loss])\n",
    "    # Anomalous dat\n",
    "    for batch in anomalous_data_loader:\n",
    "      batch = batch.type(torch.float).to(device='cuda:0')\n",
    "      expvals = encoder(params, batch, False, n_layers, n_qubits, q_compression)\n",
    "      loss = expvals[0].cpu().numpy() + expvals[1].cpu().numpy() + expvals[2].cpu().numpy()\n",
    "      loss_a = np.concatenate([loss_a,loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e2a59-a999-42a7-8a61-70a21743df73",
   "metadata": {
    "id": "850e2a59-a999-42a7-8a61-70a21743df73",
    "outputId": "b962f4aa-8571-4f83-d3ca-05c93a5abc14"
   },
   "outputs": [],
   "source": [
    "# Loss function plot (we use the loss as anomaly score)\n",
    "plt.hist(loss_a, bins=60, histtype=\"step\", color=\"red\", label=\"Anomalous data\")\n",
    "plt.hist(loss_s, bins=60, histtype=\"step\", color=\"blue\", label=\"Normal data\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.xlabel(\"Loss value\")\n",
    "plt.title(\"Loss function distribution (MNIST dataset)\")\n",
    "plt.legend()\n",
    "#file_plot = \"loss_distribution.png\"\n",
    "#plt.savefig(file_plot)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c9dde0-0a7f-48db-819b-407a526e354d",
   "metadata": {
    "id": "94c9dde0-0a7f-48db-819b-407a526e354d",
    "outputId": "82d8c5a8-6de1-4e37-e426-c10c2b8ef9c1"
   },
   "outputs": [],
   "source": [
    "# Compute and Plot the ROC Curve\n",
    "max1 = np.amax(loss_s)\n",
    "max2 = np.amax(loss_a)\n",
    "ma = max(max1, max2)\n",
    "min1 = np.amin(loss_s)\n",
    "min2 = np.amin(loss_a)\n",
    "mi = min(min1, min2)\n",
    "\n",
    "tot_neg = len(loss_s)\n",
    "tot_pos = len(loss_a)\n",
    "\n",
    "n_step = 100.0\n",
    "n_step_int = 100\n",
    "step = (ma - mi) / n_step\n",
    "fpr = []\n",
    "tpr = []\n",
    "for i in range(n_step_int):\n",
    "    treshold = i * step + mi\n",
    "    c = 0\n",
    "    for j in range(tot_neg):\n",
    "        if loss_s[j] > treshold:\n",
    "            c += 1\n",
    "    false_positive = c / float(tot_neg)\n",
    "    fpr.append(false_positive)\n",
    "    c = 0\n",
    "    for j in range(tot_pos):\n",
    "        if loss_a[j] > treshold:\n",
    "            c += 1\n",
    "    true_positive = c / float(tot_pos)\n",
    "    tpr.append(true_positive)\n",
    "\n",
    "plt.title(\"Receiver Operating Characteristic\")\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "#file_plot = \"ROC.png\"\n",
    "#plt.savefig(file_plot)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d820d-20ce-4ecd-841c-cc05e2602bb2",
   "metadata": {
    "id": "c70d820d-20ce-4ecd-841c-cc05e2602bb2",
    "outputId": "68664931-3cfb-45c5-dac4-03fa0b1023a2"
   },
   "outputs": [],
   "source": [
    "# Decoder\n",
    "# we can simply obtain the Decoder as adjoint (eg transpose conjugate) of the encoder unitary\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def decoder(params, state, n_layers, n_qubits, q_compression):\n",
    "    # Prepare initial state\n",
    "    qml.QubitStateVector(state, wires=range(n_qubits))\n",
    "\n",
    "    # Real quantum encoding (using amplitude encoding). If you want to use it comment previous line and uncomment this ...\n",
    "    #qml.AmplitudeEmbedding(features=state, wires=range(n_qubits))\n",
    "\n",
    "\n",
    "    # Quantum circuit (encoder inverse)\n",
    "    qml.adjoint(encoder_architecture)(params,  n_layers, n_qubits, q_compression) #qml.adjoint compute the transpose conjugate to an input unitary\n",
    "    return qml.state()\n",
    "\n",
    "def prepare_decoder_input(latent_space):\n",
    "  decoder_input = np.zeros((64,), dtype=complex)\n",
    "  decoder_input[-len(latent_space):] = latent_space\n",
    "  # Normalize\n",
    "  norm = np.linalg.norm(decoder_input)\n",
    "  decoder_input = decoder_input/norm\n",
    "  return torch.tensor(decoder_input)\n",
    "\n",
    "# Visualize_decoder\n",
    "qml.drawer.use_style(\"black_white\")\n",
    "fig, ax = qml.draw_mpl(decoder)(params, normal_data_test[0], n_layers, n_qubits, q_compression)\n",
    "plt.title(\"Decoder\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53f3a6-b718-4001-b636-c53fa465bd09",
   "metadata": {
    "id": "ea53f3a6-b718-4001-b636-c53fa465bd09",
    "outputId": "03a31bbd-1832-4892-a201-f89ca194bb4a"
   },
   "outputs": [],
   "source": [
    "# example on how to use the full outencoder to reconstruct examples\n",
    "\n",
    "compression = 56 # for 3 out of 6 compressed qubits: compression = 2^5+2^4+2^3\n",
    "sample = normal_data_test[0] # reconstruct 0\n",
    "#sample = anomalous_data_test[0] #reconstruct 1\n",
    "plt.imshow(np.reshape(sample, (8,8)), cmap=\"gray\")\n",
    "plt.title(\"Original\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "with torch.no_grad():\n",
    "  final_state = encoder(params=params, state=sample, return_state=True, n_layers=n_layers, n_qubits=n_qubits, q_compression=q_compression).cpu().numpy()\n",
    "  latent_space = final_state[compression:]\n",
    "  decoder_input = prepare_decoder_input(latent_space)\n",
    "  decoder_input = decoder_input.to(device='cuda:0')\n",
    "  reconstructed = np.absolute(decoder(params, decoder_input, n_layers, n_qubits, q_compression).cpu().numpy())\n",
    "plt.imshow(np.reshape(reconstructed, (8,8)), cmap=\"gray\")\n",
    "plt.title(\"Reconstructed\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "qml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
