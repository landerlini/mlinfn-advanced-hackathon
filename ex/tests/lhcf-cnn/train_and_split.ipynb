{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37529d65-4ca2-4e05-985d-9472f080872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA_DIR=/tmp/lhcf-cnn\n",
    "\n",
    "if [ ! -d $DATA_DIR ]; then\n",
    "  mkdir -p $DATA_DIR\n",
    "fi\n",
    "\n",
    "if [ ! -f $DATA_DIR/combined_data.h5 ]; then\n",
    "  wget https://minio.131.154.99.37.myip.cloud.infn.it/hackathon-data/lhcf-cnn/combined_data.h5 -O $DATA_DIR/combined_data.h5 &> .log\n",
    "fi\n",
    "\n",
    "ls -lrth $DATA_DIR/combined_data.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be18833-f200-405a-97d9-deb8f20a1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from multiprocessing import Pool, Manager\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7987f937-9a2f-4e9c-b9a8-b95e6b387ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/tmp/lhcf-cnn\"\n",
    "REDU_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37653dc3-5eb2-4e44-8ea2-3e0f5715a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare un esempio TFRecord\n",
    "def create_tfrecord_example(posdE_01xy, posdE_23x, posdE_23y, dE, label):\n",
    "    features = {\n",
    "        \"posdE_01xy\": tf.train.Feature(float_list=tf.train.FloatList(value=posdE_01xy.reshape(-1))),\n",
    "        \"posdE_23x\": tf.train.Feature(float_list=tf.train.FloatList(value=posdE_23x.reshape(-1))),\n",
    "        \"posdE_23y\": tf.train.Feature(float_list=tf.train.FloatList(value=posdE_23y.reshape(-1))),\n",
    "        \"dE\": tf.train.Feature(float_list=tf.train.FloatList(value=dE.reshape(-1))),\n",
    "        \"label\": tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=features))\n",
    "\n",
    "\n",
    "# Funzione per scrivere un batch di esempi in un file TFRecord con aggiornamento della barra di avanzamento\n",
    "def write_tfrecord_batch(h5_file_path, indices, tfrecord_file_path, progress_queue):\n",
    "    with h5py.File(h5_file_path, \"r\") as f, tf.io.TFRecordWriter(tfrecord_file_path) as writer:\n",
    "        for i in indices:\n",
    "            posdE_01xy = f[\"posdE_01xy\"][i].astype(\"float32\")\n",
    "            posdE_23x = f[\"posdE_23x\"][i].astype(\"float32\")\n",
    "            posdE_23y = f[\"posdE_23y\"][i].astype(\"float32\")\n",
    "            dE = f[\"dE\"][i, :, 0].astype(\"float32\")  # Rimuove la dimensione extra\n",
    "            label = int(f[\"ID\"][i])\n",
    "            \n",
    "            example = create_tfrecord_example(posdE_01xy, posdE_23x, posdE_23y, dE, label)\n",
    "            writer.write(example.SerializeToString())\n",
    "            progress_queue.put(1)  # Aggiorna la barra di avanzamento\n",
    "\n",
    "\n",
    "# Funzione per mostrare lo stato di avanzamento\n",
    "def progress_listener(total_samples, progress_queue):\n",
    "    with tqdm(total=total_samples, desc=\"Conversione in TFRecord\") as pbar:\n",
    "        for _ in range(total_samples):\n",
    "            progress_queue.get()\n",
    "            pbar.update(1)\n",
    "\n",
    "\n",
    "# Funzione principale per dividere il dataset e scrivere in parallelo con la barra di avanzamento\n",
    "def split_and_parallel_write(h5_file_path, train_tfrecord_path, val_tfrecord_path, train_ratio=0.8, num_processes=4):\n",
    "    with h5py.File(h5_file_path, \"r\") as f:\n",
    "        n_samples = f[\"ID\"].shape[0]\n",
    "        indices = np.arange(n_samples)[:REDU_SIZE]\n",
    "        train_indices, val_indices = train_test_split(indices, test_size=1 - train_ratio, random_state=42, shuffle=True)\n",
    "\n",
    "    # Suddividi gli indici in batch per la parallelizzazione\n",
    "    train_batches = np.array_split(train_indices, num_processes)\n",
    "    val_batches = np.array_split(val_indices, num_processes)\n",
    "\n",
    "    # Gestore per la barra di avanzamento con multiprocessing\n",
    "    manager = Manager()\n",
    "    progress_queue = manager.Queue()\n",
    "\n",
    "    # Avvia il processo della barra di avanzamento\n",
    "    total_samples = len(train_indices) + len(val_indices)\n",
    "    progress_process = Pool(1, progress_listener, (total_samples, progress_queue))\n",
    "\n",
    "    # Scrittura parallela dei file TFRecord\n",
    "    with Pool(num_processes) as pool:\n",
    "        pool.starmap(write_tfrecord_batch, [(h5_file_path, batch, f\"{train_tfrecord_path}_part{i}\", progress_queue) for i, batch in enumerate(train_batches)])\n",
    "        pool.starmap(write_tfrecord_batch, [(h5_file_path, batch, f\"{val_tfrecord_path}_part{i}\", progress_queue) for i, batch in enumerate(val_batches)])\n",
    "\n",
    "    # Termina il processo della barra di avanzamento\n",
    "    progress_process.close()\n",
    "    progress_process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf207197-e98f-4451-8b78-4764e7d77adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_fname = f\"{PATH}/combined_data.h5\"\n",
    "exp_dirname = f\"{PATH}/Train_and_Validation\"\n",
    "\n",
    "if not os.path.exists(exp_dirname):\n",
    "    os.makedirs(exp_dirname)\n",
    "else:\n",
    "    shutil.rmtree(exp_dirname)\n",
    "    os.makedirs(exp_dirname)\n",
    "\n",
    "# Esegui la conversione usando pi√π processi con barra di avanzamento\n",
    "split_and_parallel_write(src_fname, f\"{exp_dirname}/train.tfrecord\", f\"{exp_dirname}/validation.tfrecord\", num_processes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deabb18-ff84-4a10-97bd-5d1596764e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per concatenare i file TFRecord con una barra di avanzamento\n",
    "def concatenate_tfrecords(input_files, output_file):\n",
    "    total_records = sum(1 for input_file in input_files for _ in tf.data.TFRecordDataset(input_file))\n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_file) as writer:\n",
    "        with tqdm(total=total_records, desc=f\"Concatenazione {output_file}\") as pbar:\n",
    "            for input_file in input_files:\n",
    "                for record in tf.data.TFRecordDataset(input_file):\n",
    "                    writer.write(record.numpy())\n",
    "                    pbar.update(1)\n",
    "    print(f\"File TFRecord concatenato salvato: {output_file}\")\n",
    "\n",
    "# Ottieni la lista dei file TFRecord di train e validation\n",
    "train_files = sorted([os.path.join(exp_dirname, f) for f in os.listdir(exp_dirname) if f.startswith(\"train.tfrecord_part\")])\n",
    "validation_files = sorted([os.path.join(exp_dirname, f) for f in os.listdir(exp_dirname) if f.startswith(\"validation.tfrecord_part\")])\n",
    "\n",
    "# Concatena i file in un singolo TFRecord per train e validation con la barra di avanzamento\n",
    "concatenate_tfrecords(train_files, f\"{PATH}/train.tfrecord\")\n",
    "concatenate_tfrecords(validation_files, f\"{PATH}/validation.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3eae19-7a29-4d18-89e5-d666871e0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls -lrth /tmp/lhcf-cnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-k2",
   "language": "python",
   "name": "cnn-k2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
