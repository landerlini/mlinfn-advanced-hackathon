{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19954e7-097a-4fe8-8347-6a8ca91fb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv1D, Dense,  MaxPooling2D, MaxPooling1D, Flatten, Concatenate, GlobalAveragePooling2D, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221ae551-33e7-4a8c-952f-13c84b9887bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/tmp/lhcf-cnn\"\n",
    "EPOCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998cc2b-5327-490a-b963-49f6da92eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci lo schema del TFRecord\n",
    "feature_description = {\n",
    "    \"posdE_01xy\": tf.io.FixedLenFeature([384 * 384 * 2], tf.float32),\n",
    "    \"posdE_23x\": tf.io.FixedLenFeature([384 * 2], tf.float32),\n",
    "    \"posdE_23y\": tf.io.FixedLenFeature([384 * 2], tf.float32),\n",
    "    \"dE\": tf.io.FixedLenFeature([16], tf.float32),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "# Funzione per il parsing dei record\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Ricostruisci le forme originali\n",
    "    posdE_01xy = tf.reshape(example[\"posdE_01xy\"], (384, 384, 2))\n",
    "    posdE_23x = tf.reshape(example[\"posdE_23x\"], (384, 2))\n",
    "    posdE_23y = tf.reshape(example[\"posdE_23y\"], (384, 2))\n",
    "    dE = tf.reshape(example[\"dE\"], (16,))\n",
    "    label = example[\"label\"]\n",
    "    \n",
    "    return {\"posdE_01xy_input\": posdE_01xy, \"posdE_23x_input\": posdE_23x, \"posdE_23y_input\": posdE_23y, \"dE_input\": dE}, label\n",
    "\n",
    "# Carica e pre-processa i dati in batch\n",
    "def load_dataset(tfrecord_file, batch_size=32, shuffle_buffer=1000):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle_buffer==None:\n",
    "        dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        dataset = dataset.shuffle(shuffle_buffer).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Creazione dei dataset di training e validazione\n",
    "train_dataset = load_dataset(f\"{PATH}/train.tfrecord\", batch_size=32)\n",
    "validation_dataset = load_dataset(f\"{PATH}/validation.tfrecord\", batch_size=32, shuffle_buffer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ca35c-c1fc-4e20-a0e1-4632200b8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef42b2-9f3b-418b-bd01-20e969909ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_noshuffle = load_dataset(f\"{PATH}/train.tfrecord\", batch_size=32, shuffle_buffer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e731b03-5e5a-4be3-b3bd-13b5c7a77e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta il numero di esempi con label 0 e 1 nel train_dataset\n",
    "count_label_0 = 0\n",
    "count_label_1 = 0\n",
    "\n",
    "# Itera su train_dataset per contare le label\n",
    "for _, labels in train_dataset_noshuffle:\n",
    "    # Converte i tensor delle label in numpy per operazioni semplici\n",
    "    labels_numpy = labels.numpy()\n",
    "    count_label_0 += np.sum(labels_numpy == 0)\n",
    "    count_label_1 += np.sum(labels_numpy == 1)\n",
    "\n",
    "print(f\"Numero di esempi con label 0: {count_label_0}\")\n",
    "print(f\"Numero di esempi con label 1: {count_label_1}\")\n",
    "ratio = count_label_0/ count_label_1\n",
    "print(\"Rapporto: \",ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031bea0-c3f3-419d-b75a-26153fa97c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai un batch dal dataset\n",
    "for batch in train_dataset_noshuffle.take(1):  # Prende il primo batch\n",
    "    example = batch[0]  # Prende le feature\n",
    "    label = batch[1]  # Prende la label\n",
    "    break\n",
    "\n",
    "# Estrai un singolo esempio\n",
    "posdE_01xy_example = example[\"posdE_01xy_input\"].numpy()[2]  # Prende il primo esempio del batch\n",
    "\n",
    "# Visualizza l'immagine posdE_01xy_input\n",
    "plt.imshow(posdE_01xy_example[:, :, 0], cmap='viridis')  # Visualizza il primo canale\n",
    "plt.colorbar()\n",
    "plt.title(\"posdE_01xy_input - Piano 1\")\n",
    "plt.show()\n",
    "\n",
    "# Per visualizzare il secondo canale separatamente\n",
    "plt.imshow(posdE_01xy_example[:, :, 1], cmap='viridis')  # Visualizza il secondo canale\n",
    "plt.colorbar()\n",
    "plt.title(\"posdE_01xy_input - Piano 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312903f-3c2d-4013-b2bd-915edde99ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai un batch dal dataset\n",
    "for batch in train_dataset_noshuffle.take(1):  # Prende il primo batch\n",
    "    example = batch[0]  # Prende le feature\n",
    "    label = batch[1]  # Prende la label\n",
    "    break\n",
    "\n",
    "# Estrai un singolo esempio\n",
    "posdE_23x_example = example[\"posdE_23x_input\"].numpy()[2]  # Prende il primo esempio del batch\n",
    "\n",
    "# Visualizza i due canali come linee separate\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(posdE_23x_example[:, 0], label=\"Piano 2\")\n",
    "plt.plot(posdE_23x_example[:, 1], label=\"Piano 3\")\n",
    "plt.title(\"posdE_23x_input\")\n",
    "plt.xlabel(\"Indice\")\n",
    "plt.ylabel(\"Valore\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802779fe-7ebc-4ece-a0c2-d18142fec233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai un batch dal dataset\n",
    "for batch in train_dataset_noshuffle.take(1):  # Prende il primo batch\n",
    "    example = batch[0]  # Prende le feature\n",
    "    label = batch[1]  # Prende la label\n",
    "    break\n",
    "\n",
    "# Estrai un singolo esempio\n",
    "posdE_23y_example = example[\"posdE_23y_input\"].numpy()[2]  # Prende il primo esempio del batch\n",
    "\n",
    "# Visualizza i due canali come linee separate\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(posdE_23y_example[:, 0], label=\"Piano 2\")\n",
    "plt.plot(posdE_23y_example[:, 1], label=\"Piano 3\")\n",
    "plt.title(\"posdE_23y_input\")\n",
    "plt.xlabel(\"Indice\")\n",
    "plt.ylabel(\"Valore\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9317e71-85cc-4ae4-be4f-7ed8036fa4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estrai un batch dal dataset\n",
    "for batch in train_dataset_noshuffle.take(1):  # Prende il primo batch\n",
    "    example = batch[0]  # Prende le feature\n",
    "    label = batch[1]  # Prende la label\n",
    "    break\n",
    "\n",
    "# Estrai un singolo esempio di dE_input\n",
    "dE_example = example[\"dE_input\"].numpy()[2]  # Prende il primo esempio del batch\n",
    "\n",
    "# Visualizza dE_input come grafico a barre\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(len(dE_example)), dE_example)\n",
    "plt.title(\"dE_input\")\n",
    "plt.xlabel(\"Indice\")\n",
    "plt.ylabel(\"Valore\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5666d36-2e49-47a6-a28b-a7a00fb76408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione della rete neurale\n",
    "\n",
    "# Input per Conv2D con GlobalAveragePooling\n",
    "input_posdE_01xy = Input(shape=(384, 384, 2), name=\"posdE_01xy_input\")\n",
    "x1 = Conv2D(4, (3, 3), activation=\"relu\", padding=\"same\")(input_posdE_01xy)\n",
    "x1 = MaxPooling2D((2, 2))(x1)\n",
    "#x1 = GlobalAveragePooling2D()(x1)  # Riducono i parametri\n",
    "x1 = Flatten()(x1) \n",
    "\n",
    "# Input per Conv1D con GlobalAveragePooling\n",
    "input_posdE_23x = Input(shape=(384, 2), name=\"posdE_23x_input\")\n",
    "x2 = Conv1D(4, 3, activation=\"relu\", padding=\"same\")(input_posdE_23x)\n",
    "x2 = MaxPooling1D(2)(x2)\n",
    "#x2 = GlobalAveragePooling1D()(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "input_posdE_23y = Input(shape=(384, 2), name=\"posdE_23y_input\")\n",
    "x3 = Conv1D(4, 3, activation=\"relu\", padding=\"same\")(input_posdE_23y)\n",
    "x3 = MaxPooling1D(2)(x3)\n",
    "#x3 = GlobalAveragePooling1D()(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "# Input per Dense\n",
    "input_dE = Input(shape=(16,), name=\"dE_input\")\n",
    "x4 = Dense(4, activation=\"relu\")(input_dE)\n",
    "\n",
    "# Concatenazione delle rappresentazioni dei quattro blocchi\n",
    "x = Concatenate()([x1, x2, x3, x4])\n",
    "\n",
    "# Output per classificazione binaria\n",
    "output = Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "# Definisci il modello\n",
    "model = Model(inputs=[input_posdE_01xy, input_posdE_23x, input_posdE_23y, input_dE], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4be45f-4115-4ec3-a5a7-33150333b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila il modello\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Visualizza il sommario del modello\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2919d8-7c3f-4c57-9110-acf409f91e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a68ed-46d9-481b-8cf6-498775584401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Definisci i pesi per le classi\n",
    "#class_weight = {0: 1, 1: 3}  \n",
    "\n",
    "# Allena il modello\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCH,\n",
    "    #class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23330c7-3365-4e85-a08d-7322d78e2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9d168-49f0-48bd-94c1-27619985ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_loss'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1ba7c-5563-425b-a582-59dc1c896634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola le etichette e le predizioni per il dataset di training senza shuffle\n",
    "y_train_true = np.concatenate([y for _, y in train_dataset_noshuffle.as_numpy_iterator()], axis=0)\n",
    "train_predictions = model.predict(train_dataset_noshuffle)\n",
    "\n",
    "# Dividi le predizioni del training in base alle etichette\n",
    "train_predictions_0 = train_predictions[y_train_true == 0]\n",
    "train_predictions_1 = train_predictions[y_train_true == 1]\n",
    "\n",
    "# Calcola le etichette e le predizioni per il dataset di validazione senza shuffle\n",
    "y_val_true = np.concatenate([y for _, y in validation_dataset.as_numpy_iterator()], axis=0)\n",
    "val_predictions = model.predict(validation_dataset)\n",
    "\n",
    "# Dividi le predizioni della validazione in base alle etichette\n",
    "val_predictions_0 = val_predictions[y_val_true == 0]\n",
    "val_predictions_1 = val_predictions[y_val_true == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299e218-158c-41c8-b0af-065d25231c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottaggio degli istogrammi normalizzati\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Istogramma per train_predictions_label_0 e train_predictions_label_1\n",
    "# Normalizza ciascun istogramma affinché l'area totale sia 1\n",
    "train_hist_0, bins_0, _ = plt.hist(train_predictions_0, bins=100, alpha=0.4, color='darkorange', label='Train - Label 0', edgecolor='black', density=True)\n",
    "train_hist_1, bins_1, _ = plt.hist(train_predictions_1, bins=100, alpha=0.4, color='blue', label='Train - Label 1', edgecolor='black', density=True)\n",
    "\n",
    "# Istogrammi per la validazione (senza visualizzazione)\n",
    "val_hist_0, bin_val_0 = np.histogram(val_predictions_0, bins=100, density=True)\n",
    "val_hist_1, bin_val_1 = np.histogram(val_predictions_1, bins=100, density=True)\n",
    "\n",
    "plt.plot(bin_val_0[1:], val_hist_0, '*', color='darkorange', label='Validation - Label 0')\n",
    "plt.plot(bin_val_1[1:], val_hist_1, '*', color='blue', label='Validation - Label 1')\n",
    "\n",
    "# Aggiungi etichette e legenda\n",
    "plt.xlabel(\"Valori delle Predizioni\")\n",
    "plt.ylabel(\"Densità Normalizzata\")\n",
    "plt.title(\"Istogramma Normalizzato delle Predizioni per Train e Validation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcd0af-abf5-4bfc-b79f-cbf26390e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Predizione per l'intero dataset \n",
    "#y_train_true = np.concatenate([y for _, y in train_dataset_noshuffle.as_numpy_iterator()], axis=0)\n",
    "#train_predictions = model.predict(train_dataset_noshuffle)\n",
    "y_train_pred = (train_predictions >= 0.5).astype(int)\n",
    "\n",
    "#y_val_true = np.concatenate([y for _, y in validation_dataset.as_numpy_iterator()], axis=0)\n",
    "#val_predictions = model.predict(validation_dataset)\n",
    "y_val_pred = (val_predictions >= 0.5).astype(int)\n",
    "\n",
    "# Calcola la matrice di confusione per il training\n",
    "train_cm = confusion_matrix(y_train_true, y_train_pred)\n",
    "ConfusionMatrixDisplay(train_cm, display_labels=['Label 0', 'Label 1']).plot()\n",
    "plt.title('Confusion Matrix - Training')\n",
    "plt.show()\n",
    "\n",
    "# Calcola la matrice di confusione per la validazione\n",
    "val_cm = confusion_matrix(y_val_true, y_val_pred)\n",
    "ConfusionMatrixDisplay(val_cm, display_labels=['Label 0', 'Label 1']).plot()\n",
    "plt.title('Confusion Matrix - Validation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-k2",
   "language": "python",
   "name": "cnn-k2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
