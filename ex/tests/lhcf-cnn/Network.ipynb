{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19954e7-097a-4fe8-8347-6a8ca91fb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv1D, Dense,  MaxPooling2D, MaxPooling1D, Flatten, Concatenate, GlobalAveragePooling2D, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4b690-2175-4efe-9a66-2b82bfa8d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16545e41-852d-424d-bf80-9c4d09fa4c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/tmp/lhcf-cnn\"\n",
    "\n",
    "EPOCH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998cc2b-5327-490a-b963-49f6da92eac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the TFRecord schema\n",
    "feature_description = {\n",
    "    \"posdE_01xy\": tf.io.FixedLenFeature([384 * 384 * 2], tf.float32),\n",
    "    \"posdE_23x\": tf.io.FixedLenFeature([384 * 2], tf.float32),\n",
    "    \"posdE_23y\": tf.io.FixedLenFeature([384 * 2], tf.float32),\n",
    "    \"dE\": tf.io.FixedLenFeature([16], tf.float32),\n",
    "    \"label\": tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "# Function to parse TFRecord records\n",
    "def parse_tfrecord_fn(example_proto):\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    \n",
    "    # Reconstruct the original shapes\n",
    "    posdE_01xy = tf.reshape(example[\"posdE_01xy\"], (384, 384, 2))\n",
    "    posdE_23x = tf.reshape(example[\"posdE_23x\"], (384, 2))\n",
    "    posdE_23y = tf.reshape(example[\"posdE_23y\"], (384, 2))\n",
    "    dE = tf.reshape(example[\"dE\"], (16,))\n",
    "    label = example[\"label\"]\n",
    "    \n",
    "    return {\"posdE_01xy_input\": posdE_01xy, \"posdE_23x_input\": posdE_23x, \"posdE_23y_input\": posdE_23y, \"dE_input\": dE}, label\n",
    "\n",
    "# Load and preprocess data in batches\n",
    "def load_dataset(tfrecord_file, batch_size=32, shuffle_buffer=1000):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle_buffer == None:\n",
    "        dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        dataset = dataset.shuffle(shuffle_buffer).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset = load_dataset(f\"{PATH}/train.tfrecord\", batch_size=32)\n",
    "validation_dataset = load_dataset(f\"{PATH}/validation.tfrecord\", batch_size=32, shuffle_buffer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022ca35c-c1fc-4e20-a0e1-4632200b8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef42b2-9f3b-418b-bd01-20e969909ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_noshuffle = load_dataset(f\"{PATH}/train.tfrecord\", batch_size=32, shuffle_buffer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e731b03-5e5a-4be3-b3bd-13b5c7a77e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of examples with label 0 and 1 in the train_dataset\n",
    "count_label_0 = 0\n",
    "count_label_1 = 0\n",
    "\n",
    "# Iterate over the train_dataset to count the labels\n",
    "for _, labels in train_dataset:\n",
    "    # Convert the label tensors to numpy for easy operations\n",
    "    labels_numpy = labels.numpy()\n",
    "    count_label_0 += np.sum(labels_numpy == 0)\n",
    "    count_label_1 += np.sum(labels_numpy == 1)\n",
    "\n",
    "print(f\"Number of examples with label 0: {count_label_0}\")\n",
    "print(f\"Number of examples with label 1: {count_label_1}\")\n",
    "ratio = count_label_0 / count_label_1\n",
    "print(\"Ratio: \", ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e031bea0-c3f3-419d-b75a-26153fa97c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a batch from the dataset\n",
    "for batch in train_dataset_noshuffle.take(1):  # Take the first batch\n",
    "    example = batch[0]  # Extract features\n",
    "    label = batch[0]  # Extract labels\n",
    "    break\n",
    "\n",
    "# Extract a single example\n",
    "posdE_01xy_example = example[\"posdE_01xy_input\"].numpy()[2]  # Get the second example from the batch\n",
    "\n",
    "# Visualize the image from posdE_01xy_input\n",
    "plt.imshow(posdE_01xy_example[:, :, 0], cmap='viridis')  # Display the first channel\n",
    "plt.colorbar()\n",
    "plt.title(\"posdE_01xy_input - Plane 1\")\n",
    "plt.show()\n",
    "\n",
    "# To visualize the second channel separately\n",
    "plt.imshow(posdE_01xy_example[:, :, 1], cmap='viridis')  # Display the second channel\n",
    "plt.colorbar()\n",
    "plt.title(\"posdE_01xy_input - Plane 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312903f-3c2d-4013-b2bd-915edde99ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a batch from the dataset\n",
    "for batch in train_dataset_noshuffle.take(1):  # Take the first batch\n",
    "    example = batch[0]  # Extract features\n",
    "    label = batch[0]  # Extract labels\n",
    "    break\n",
    "\n",
    "# Extract a single example\n",
    "posdE_23x_example = example[\"posdE_23x_input\"].numpy()[2]  # Get the second example from the batch\n",
    "\n",
    "# Visualize the two channels as separate lines\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(posdE_23x_example[:, 0], label=\"Plane 2\")\n",
    "plt.plot(posdE_23x_example[:, 1], label=\"Plane 3\")\n",
    "plt.title(\"posdE_23x_input\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802779fe-7ebc-4ece-a0c2-d18142fec233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a batch from the dataset\n",
    "for batch in train_dataset_noshuffle.take(1):  # Take the first batch\n",
    "    example = batch[0]  # Extract features\n",
    "    label = batch[0]  # Extract labels\n",
    "    break\n",
    "\n",
    "# Extract a single example\n",
    "posdE_23y_example = example[\"posdE_23y_input\"].numpy()[2]  # Get the second example from the batch\n",
    "\n",
    "# Visualize the two channels as separate lines\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(posdE_23y_example[:, 0], label=\"Plane 2\")\n",
    "plt.plot(posdE_23y_example[:, 1], label=\"Plane 3\")\n",
    "plt.title(\"posdE_23y_input\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9317e71-85cc-4ae4-be4f-7ed8036fa4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a batch from the dataset\n",
    "for batch in train_dataset.take(1):  # Take the first batch\n",
    "    example = batch[0]  # Extract features\n",
    "    label = batch[0]  # Extract labels\n",
    "    break\n",
    "\n",
    "# Extract a single example of dE_input\n",
    "dE_example = example[\"dE_input\"].numpy()[2]  # Get the second example from the batch\n",
    "\n",
    "# Visualize dE_input as a bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(range(len(dE_example)), dE_example)\n",
    "plt.title(\"dE_input\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5666d36-2e49-47a6-a28b-a7a00fb76408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Definition\n",
    "\n",
    "# Input for Conv2D \n",
    "input_posdE_01xy = Input(shape=(384, 384, 2), name=\"posdE_01xy_input\")\n",
    "x1 = Conv2D(4, (3, 3), activation=\"relu\", padding=\"same\")(input_posdE_01xy)\n",
    "x1 = MaxPooling2D((2, 2))(x1)\n",
    "# Uncomment this line to reduce parameters further\n",
    "# x1 = GlobalAveragePooling2D()(x1)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# Input for Conv1D \n",
    "input_posdE_23x = Input(shape=(384, 2), name=\"posdE_23x_input\")\n",
    "x2 = Conv1D(4, 3, activation=\"relu\", padding=\"same\")(input_posdE_23x)\n",
    "x2 = MaxPooling1D(2)(x2)\n",
    "# Uncomment this line to reduce parameters further\n",
    "# x2 = GlobalAveragePooling1D()(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "input_posdE_23y = Input(shape=(384, 2), name=\"posdE_23y_input\")\n",
    "x3 = Conv1D(4, 3, activation=\"relu\", padding=\"same\")(input_posdE_23y)\n",
    "x3 = MaxPooling1D(2)(x3)\n",
    "# Uncomment this line to reduce parameters further\n",
    "# x3 = GlobalAveragePooling1D()(x3)\n",
    "x3 = Flatten()(x3)\n",
    "\n",
    "# Input for Dense\n",
    "input_dE = Input(shape=(16,), name=\"dE_input\")\n",
    "x4 = Dense(4, activation=\"relu\")(input_dE)\n",
    "\n",
    "# Combine the outputs of all branches\n",
    "x = Concatenate()([x1, x2, x3, x4])\n",
    "\n",
    "# Output for binary classification\n",
    "output = Dense(1, activation=\"sigmoid\", name=\"output\")(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=[input_posdE_01xy, input_posdE_23x, input_posdE_23y, input_dE], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4be45f-4115-4ec3-a5a7-33150333b3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "from tensorflow.keras.metrics import AUC\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", AUC()])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2919d8-7c3f-4c57-9110-acf409f91e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a68ed-46d9-481b-8cf6-498775584401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define class weights (optional)\n",
    "# class_weight = {0: 1, 1: 3}\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCH,\n",
    "    # class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bddbee2-0fe9-4bda-9c09-e79fb43c1a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['auc'], label='Training AUC')\n",
    "plt.plot(history.history['val_auc'], label='Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23330c7-3365-4e85-a08d-7322d78e2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9d168-49f0-48bd-94c1-27619985ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_loss'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e1ba7c-5563-425b-a582-59dc1c896634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute true labels and predictions for the training dataset without shuffle\n",
    "y_train_true = np.concatenate([y for _, y in train_dataset_noshuffle.as_numpy_iterator()], axis=0)\n",
    "train_predictions = model.predict(train_dataset_noshuffle)\n",
    "\n",
    "# Split training predictions by labels\n",
    "train_predictions_0 = train_predictions[y_train_true == 0]\n",
    "train_predictions_1 = train_predictions[y_train_true == 1]\n",
    "\n",
    "# Compute true labels and predictions for the validation dataset without shuffle\n",
    "y_val_true = np.concatenate([y for _, y in validation_dataset.as_numpy_iterator()], axis=0)\n",
    "val_predictions = model.predict(validation_dataset)\n",
    "\n",
    "# Split validation predictions by labels\n",
    "val_predictions_0 = val_predictions[y_val_true == 0]\n",
    "val_predictions_1 = val_predictions[y_val_true == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299e218-158c-41c8-b0af-065d25231c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram for train_predictions_label_0 and train_predictions_label_1\n",
    "# Normalize each histogram so that the total area equals 1\n",
    "train_hist_0, bins_0, _ = plt.hist(\n",
    "    train_predictions_0, bins=100, alpha=0.4, color='darkorange', \n",
    "    label='Train - Label 0', edgecolor='black', density=True\n",
    ")\n",
    "train_hist_1, bins_1, _ = plt.hist(\n",
    "    train_predictions_1, bins=100, alpha=0.4, color='blue', \n",
    "    label='Train - Label 1', edgecolor='black', density=True\n",
    ")\n",
    "\n",
    "# Histograms for validation (without visualization)\n",
    "val_hist_0, bin_val_0 = np.histogram(val_predictions_0, bins=100, density=True)\n",
    "val_hist_1, bin_val_1 = np.histogram(val_predictions_1, bins=100, density=True)\n",
    "\n",
    "# Plot validation histograms\n",
    "plt.plot(bin_val_0[1:], val_hist_0, '*', color='darkorange', label='Validation - Label 0')\n",
    "plt.plot(bin_val_1[1:], val_hist_1, '*', color='blue', label='Validation - Label 1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Prediction Values\")\n",
    "plt.ylabel(\"Normalized Density\")\n",
    "plt.title(\"Normalized Histogram of Predictions for Train and Validation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcd0af-abf5-4bfc-b79f-cbf26390e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Predictions for the entire dataset\n",
    "y_train_pred = (train_predictions >= 0.5).astype(int)\n",
    "y_val_pred = (val_predictions >= 0.5).astype(int)\n",
    "\n",
    "# Compute the confusion matrix for training\n",
    "train_cm = confusion_matrix(y_train_true, y_train_pred)\n",
    "ConfusionMatrixDisplay(train_cm, display_labels=['Label 0', 'Label 1']).plot()\n",
    "plt.title('Confusion Matrix - Training')\n",
    "plt.show()\n",
    "\n",
    "# Compute the confusion matrix for validation\n",
    "val_cm = confusion_matrix(y_val_true, y_val_pred)\n",
    "ConfusionMatrixDisplay(val_cm, display_labels=['Label 0', 'Label 1']).plot()\n",
    "plt.title('Confusion Matrix - Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262c9de-dcb9-4c9c-a64a-3ecd80dc877a",
   "metadata": {},
   "source": [
    "## Test only dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01a8d9-60b9-4162-b414-571ccb308ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for Dense layer\n",
    "input_dE = Input(shape=(16,), name=\"dE_input\")\n",
    "x4 = Dense(4, activation=\"relu\")(input_dE)\n",
    "\n",
    "# Output for binary classification\n",
    "output = Dense(1, activation=\"sigmoid\", name=\"output\")(x4)\n",
    "\n",
    "# Define the model\n",
    "model_dense = Model(inputs=[input_dE], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1232c0-f872-4cee-9a68-a7e433954efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model_dense.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\", AUC()])\n",
    "\n",
    "# Display the model summary\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e29b66b-32f1-4c6d-8d04-4dfc67536aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model_dense, \"dense_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9013d67-93de-47cf-a9a6-910fcad6b127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history_dense = model_dense.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037f2aba-1de8-45fb-b801-4fb5f955feb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_dense.history['auc_1'], label='Training AUC')\n",
    "plt.plot(history_dense.history['val_auc_1'], label='Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72aef8-23f4-4a1e-8c98-75258aac37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_dense.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_dense.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d5f0f-8224-4bf5-a7bd-542c1cc451c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_dense.history['loss'], label='Training Accuracy')\n",
    "plt.plot(history_dense.history['val_loss'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531cd28-7abb-4e52-9546-b9283e48372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate labels and predictions for the training dataset without shuffle\n",
    "train_predictions_dense = model_dense.predict(train_dataset_noshuffle)\n",
    "\n",
    "# Split training predictions by labels\n",
    "train_predictions_0 = train_predictions_dense[y_train_true == 0]\n",
    "train_predictions_1 = train_predictions_dense[y_train_true == 1]\n",
    "\n",
    "# Calculate labels and predictions for the validation dataset without shuffle\n",
    "val_predictions_dense = model_dense.predict(validation_dataset)\n",
    "\n",
    "# Split validation predictions by labels\n",
    "val_predictions_0 = val_predictions_dense[y_val_true == 0]\n",
    "val_predictions_1 = val_predictions_dense[y_val_true == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad8377-61da-4bf7-97b5-46737547d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalized histograms\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Histogram for train_predictions_label_0 and train_predictions_label_1\n",
    "# Normalize each histogram so that the total area equals 1\n",
    "train_hist_0, bins_0, _ = plt.hist(\n",
    "    train_predictions_0, bins=100, alpha=0.4, color='darkorange', \n",
    "    label='Train - Label 0', edgecolor='black', density=True\n",
    ")\n",
    "train_hist_1, bins_1, _ = plt.hist(\n",
    "    train_predictions_1, bins=100, alpha=0.4, color='blue', \n",
    "    label='Train - Label 1', edgecolor='black', density=True\n",
    ")\n",
    "\n",
    "# Histograms for validation (without direct plotting)\n",
    "val_hist_0, bin_val_0 = np.histogram(val_predictions_0, bins=100, density=True)\n",
    "val_hist_1, bin_val_1 = np.histogram(val_predictions_1, bins=100, density=True)\n",
    "\n",
    "# Plot validation histograms\n",
    "plt.plot(bin_val_0[1:], val_hist_0, '*', color='darkorange', label='Validation - Label 0')\n",
    "plt.plot(bin_val_1[1:], val_hist_1, '*', color='blue', label='Validation - Label 1')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"Prediction Values\")\n",
    "plt.ylabel(\"Normalized Density\")\n",
    "plt.title(\"Normalized Histogram of Predictions for Train and Validation\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc406009-de8a-462f-9a3e-89d7a2c5f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for the entire dataset\n",
    "y_train_pred_dense = (train_predictions_dense >= 0.5).astype(int)\n",
    "y_val_pred_dense = (val_predictions_dense >= 0.5).astype(int)\n",
    "\n",
    "# Compute the confusion matrix for training\n",
    "train_cm = confusion_matrix(y_train_true, y_train_pred_dense)\n",
    "ConfusionMatrixDisplay(train_cm, display_labels=['Label 0', 'Label 1']).plot()\n",
    "plt.title('Confusion Matrix - Training')\n",
    "plt.show()\n",
    "\n",
    "# Compute the confusion matrix for validation\n",
    "val_cm = confusion_matrix(y_val_true, y_val_pred_dense)\n",
    "ConfusionMatrixDisplay(val_cm, display_labels=['Label 0', 'Label 1']).plot()\n",
    "plt.title('Confusion Matrix - Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfae6d12-a018-4caa-bb4a-9ad9d79e2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparison of roc curves from different models\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def plot_roc(X, c, model, title, fmt=''):\n",
    "  fpr, tpr, thresholds = roc_curve(c, X)\n",
    "  plt.plot(1.0 - fpr, tpr, fmt, label=f'{title} (AUC: {100*roc_auc_score(c,X):.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef507b92-df5d-492e-aecb-f79743898a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"ROC curves\", fontsize=14)\n",
    "plt.xlabel(\"True Negative Rate\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "\n",
    "plot_roc(train_predictions, y_train_true, model, 'Training Full')\n",
    "plot_roc(val_predictions, y_val_true, model, \"Validation Full\")\n",
    "plot_roc(train_predictions_dense, y_train_true, model_dense, 'Training Dense')\n",
    "plot_roc(val_predictions_dense, y_val_true, model_dense, \"Validation Dense\")\n",
    "\n",
    "plt.xlim(0.75, 1.01)\n",
    "plt.ylim(0.75, 1.01)\n",
    "plt.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn-k2",
   "language": "python",
   "name": "cnn-k2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
