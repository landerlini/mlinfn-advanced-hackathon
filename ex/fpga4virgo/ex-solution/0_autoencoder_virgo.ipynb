{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964a383e",
   "metadata": {},
   "source": [
    "<img src=\"virgo_logo.png\" alt=\"Title\" style=\"width:300px;\"/>\n",
    "\n",
    "\n",
    "# Virgo Gravitational Wave Data Exercise\n",
    "\n",
    "The aim of this exercise is to prepare a ML tool which is able to compress and clean as much as possible a dataset.\n",
    "\n",
    "**The autoencoder coded in this exercise is only used as an opportunity to acquire some insight into ML** \n",
    "\n",
    "In this exercise you will:\n",
    "\n",
    "- train a network in order to perform the job, and test their abilities\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0db6a2",
   "metadata": {},
   "source": [
    "## Gravitational Wave Data\n",
    "\n",
    "For an introduction on what GW and interferometers are please refer to https://confluence.infn.it/display/MLINFN/7.+Virgo+Autoencoder+tutorial.\n",
    "\n",
    "For a brief vocabulary see https://labcit.ligo.caltech.edu/~ll_news/0607a_news/LIGO_Vocabulary.htm.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <b>IGWN</b> stands for International Gravitational-Wave Observatory Network, it is a comunity made by three collaborations: LIGO VIRGO and KAGRA.<br />\n",
    "    <b>Strain</b> is the effect that produces an incoming gravitational wave on our detectors, which, in the case of interferometric detectors, consists of a differential variation of the arm length. This is also the observable quantity measured by the detectors.<br />\n",
    "    <b>GWF</b> stands for Gravitational Wave File and is the format IGWN used to store (not only!) interferometer strain.\n",
    "</div>\n",
    "\n",
    "All data we will use in this tutorial is freely accessibile and published by **GWOSC** (https://www.gw-openscience.org/about/). GWOSC, The Gravitational Wave Open Science Center, provides data from gravitational-wave observatories, along with tutorials and software tools. You could find there many information if you are interested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c45c5",
   "metadata": {},
   "source": [
    "## Data Access\n",
    "\n",
    "To ease the reading and decoding of the data file we had already download all data on `/data/input_data/AI_INFN/gwdata/` using a python package named `gwosc`.\n",
    "\n",
    "Gwosc aims at providing a unified and easy to use interface to access Gravitational Wave (GW) data and output some well organised datasets, ready to be used for Machine Learning projects or Data Analysis purposes (source properties, noise studies, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a7f051",
   "metadata": {},
   "source": [
    "It this exercise we will try to encode and decode our data with an **autoencoder**\n",
    "\n",
    "> [from wiki]: An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learned, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name\n",
    "\n",
    "some examples of autoencoders in keras can be found at https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "The idea is to encoding and decoding to original dimension searching for an optimum set of parameters that makes filtered signal more similar to original one. The encoded signal will retain all needed information but with a reduction of size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b28bb6",
   "metadata": {},
   "source": [
    "We will use keras ( https://keras.io/ )\n",
    "\"Keras is an API designed for human beings, not machines. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear & actionable error messages. It also has extensive documentation and developer guides.\"\n",
    "\n",
    "Some usefull info:\n",
    "\n",
    "- https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "- https://keras.io/api/models/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3f869",
   "metadata": {},
   "source": [
    "Some layers used in keras:\n",
    "\n",
    "- **Dense** layer makes output=activation(dot(input, kernel) + bias) where kernel is the matrix of parameters and activation is the activation function. Each node is fed by the whole input!\n",
    "\n",
    "- **Conv1D** layer applies a one-dimensional convolution to sequence data to extract local features along the temporal or spatial dimension. \n",
    "\n",
    "- **Dropout** layer randomly sets input units to 0 with a frequency of rate at each step during training time. Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all inputs is unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed011d26",
   "metadata": {},
   "source": [
    "*Please remember, before process data with machine learning tecniques it is really important to normalize and resample at a fixed rate all the data. That's why we explained in the introduction how to do it*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab19c23a-0d3d-440b-b076-14a86ab9e0e1",
   "metadata": {},
   "source": [
    "## Simple autoencoder example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae9c57-1b77-4052-90be-708df0a1827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a664f8-a20e-4816-8166-242f4dfd58eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7256bf-9ebe-4958-a6e3-848d8c733b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the size of our encoded representations\n",
    "original_dim = 128\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 4.0, assuming the input is 128 floats\n",
    "\n",
    "# This is our input image\n",
    "input_signal = keras.Input(shape=(original_dim,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='sigmoid')(input_signal)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(original_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_signal, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7796ef99-eddc-487f-a5d2-c78254311a15",
   "metadata": {},
   "source": [
    "The code in the previous cell defines an autoencoder model that reduces the sample size from 128 elements to 32 (encoding) and then reconstructs it back from 32 to 128 (decoding). To train the model, you need to define a training and a test dataset, and execute the `fit` instruction.\n",
    "```\n",
    "autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")\n",
    "```\n",
    "To apply inference on real data, (i.e. encode and decode data) you can execute the `predict` instruction:\n",
    "\n",
    "```\n",
    "decoded_data = autoencoder.predict(original_data)\n",
    "```\n",
    "\n",
    "Let's create a random input signal() mean=0 std=3) of 128*1000 elements to test the model\n",
    "\n",
    "```\n",
    "original_dim\n",
    "noise = np.random.normal(0, 3, original_dim*1000)\n",
    "X_signal = noise.reshape((1000, original_dim))\n",
    "x_train = X_signal[900:]\n",
    "```\n",
    "Try to train the model on this data and then apply inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea289b2-45e8-4210-a37d-233bb283c943",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim\n",
    "noise = np.random.normal(0, 3, original_dim*1000)\n",
    "X_signal = noise.reshape((1000, original_dim))\n",
    "x_train = X_signal[900:,:]\n",
    "x_test = X_signal[900:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df2502-3919-4f94-9549-0e44ced9a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788d08c1-102a-4318-b5bd-76797fceca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56154109",
   "metadata": {},
   "source": [
    "## Exercise 1 Simple autoencoder whith convoluzion layer on random sample\n",
    "\n",
    "Use the previous model, adding one convolution layer. The workflow will be the following:\n",
    "```\n",
    "original -> convolution -> encoded size 32 ->  encoded size 16 -> decoded size 32 -> decoded size original\n",
    "```\n",
    "It is convenient to play a bit with layers that expect a different number of dimension in this case\n",
    "\n",
    "Conv1D expects a 3d signal, for this reason we will add a singleton dimension doing\n",
    "\n",
    "```\n",
    "shape=(original_dim,1)\n",
    "```\n",
    "\n",
    "please note the \"1\" added to the list of the dimension\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "input_signal = keras.Input(shape=(original_dim,1))\n",
    "convolved = layers.Conv1D(filters=64, kernel_size=3, strides=1, padding=\"causal\", activation='sigmoid')(input_signal)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5722d330-7eef-45bc-b317-8bdd15a7fd7e",
   "metadata": {},
   "source": [
    "### Create input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6518db5a-7e55-425b-ab75-cb20dbfbc095",
   "metadata": {},
   "source": [
    "Create a random signal of 1000 samples (1D vectors) with 128 elements each using NumPy (np.random). Then split the created dataset into x_train (900 samples) and x_test (100 samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4f6479-0797-4216-84ba-72428046c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape to fit data\n",
    "# process the data to fit in a keras CNN properly\n",
    "# input data needs to be (N, C, X) - shaped where\n",
    "# N - number of samples\n",
    "# C - singleton dimension\n",
    "# X - sample size\n",
    "\n",
    "#let's create a random input signal() mean=0 std=3) of 128*1000 elements. Why it is multiple of 128?\n",
    "noise = np.random.normal(0, 3, original_dim*1000)\n",
    "X_signal = noise.reshape((1000, original_dim, 1))\n",
    "x_train = X_signal[0:900,:,:]\n",
    "x_test = X_signal[900:,:,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff82c8f-f856-475b-8cc9-0501c4f1e01a",
   "metadata": {},
   "source": [
    "PLot the data with matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0f3ced-fa71-4d04-ad8b-63e03a68beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36492ae9-a039-4562-a949-6524f32d4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d1ace4-4854-4737-8b3d-6e5dece653e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_signal[0,:,0], label='Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31584e2-2b58-44fc-bec7-1100f372d699",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "\n",
    "Then create the model with the following dimension:\n",
    "```\n",
    "original_dim = 128\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 4.0, assuming the input is 128 floats\n",
    "encoding_dim_1 = 16  # 16 floats -> compression of factor 8.0, assuming the input is 128 floats\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f1783-cb40-4e63-b8d6-c2818019bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the size of our encoded representations\n",
    "original_dim = 128\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 4.0, assuming the input is 128 floats\n",
    "encoding_dim_1 = 16  # 16 floats -> compression of factor 8.0, assuming the input is 128 floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b225c7-5686-48cd-a1be-be538ea34837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our input image\n",
    "input_signal = keras.Input(shape=(original_dim,1))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "convolved = layers.Conv1D(64, kernel_size=3, strides=1, padding='causal' , activation='relu')(input_signal)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(convolved)\n",
    "encoded_1 = layers.Dense(encoding_dim_1, activation='relu')(encoded)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded_1 = layers.Dense(encoding_dim, activation='sigmoid')(encoded_1)\n",
    "decoded = layers.Dense(original_dim, activation='sigmoid')(decoded_1)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_signal, decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b91e59-7392-427a-a5d2-9eb0c5eac84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode with a batch of 50 rows (how many iterations?) for 15 times...\n",
    "autoencoder.fit(x_train, x_train, epochs=15, batch_size=30, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86d26a",
   "metadata": {},
   "source": [
    "Now use the model as encoder or decoder to split the model in two and execute the `predict` instruction on each part.\n",
    "Plot the decoded data: why is so different from original?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2856fd8-8521-4e76-88a7-72385a2d11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Model(input_signal, encoded_1)\n",
    "decoder = keras.Model(encoded_1, decoded)\n",
    "\n",
    "encoded_data = encoder.predict(X_signal[:,:,:])\n",
    "decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "plt.plot(decoded_data[0,:,0], label='Sample')\n",
    "plt.plot(decoded_data[0,:,0], label='Sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bec2c6-950e-4daf-b454-2c804390f9cd",
   "metadata": {},
   "source": [
    "## Excercise 2: Encoder and decoder on MNIST database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1f2821-b57c-41b7-9c59-862a96f2d4d9",
   "metadata": {},
   "source": [
    "In this exercise, you are asked to download the MNIST dataset (28x28 pixel 2D images of handwritten digits, each pixel with a value from 0 to 255) and train an autoencoder on it:\n",
    "```\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "```\n",
    "\n",
    "Build an autoencoder that takes 28x28 matrices as input and performs a Flatten operation. Then, add two Dense layers that reduce the dimension first to 128 units, and then to 32 units.\n",
    "\n",
    "The decoding process should be done through two Dense layers that bring the sample back to its original size (after Flattening), and finally, add a Reshape layer to bring the sample back to 28x28 elements.\n",
    "\n",
    "#### Activation Functions\n",
    "\n",
    "- **Encoding**: `ReLU -> ReLU`\n",
    "- **Decoding**: `ReLU -> Sigmoid`\n",
    "\n",
    "**Note**: Since the sigmoid output ranges between 0 and 1, **the pixel intensity values must be normalized accordingly**.\n",
    "\n",
    "#### Training\n",
    "\n",
    "Train the network for 10 epochs, using the training data and validation data from the images downloaded in `(x_train, _), (x_test, _)`.\n",
    "\n",
    "#### Inference and Plotting\n",
    "\n",
    "Perform inference on a test sample and plot the result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29168b1c-4385-490f-b047-f7fe7a462bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excercise 2: Encoder and decoder on MNIST database\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e46378-a78e-4805-a4b0-c05b6eabec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalization\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Reshape in case of convolution\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "input_img = layers.Input(shape=(28, 28, 1), name=\"input_img\")\n",
    "x = layers.Flatten()(input_img)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "z = layers.Dense(latent_dim, activation='relu', name=\"latent\")(x)  # <-- Spazio \n",
    "encoder = models.Model(inputs=input_img, outputs=z, name=\"encoder\")\n",
    "\n",
    "latent_inputs = layers.Input(shape=(latent_dim,), name=\"latent_inputs\")\n",
    "x = layers.Dense(128, activation='relu')(latent_inputs)\n",
    "x = layers.Dense(28 * 28, activation='sigmoid')(x)\n",
    "decoded = layers.Reshape((28, 28, 1))(x)\n",
    "decoder = models.Model(inputs=latent_inputs, outputs=decoded, name=\"decoder\")\n",
    "\n",
    "autoencoder_input = input_img\n",
    "autoencoder_output = decoder(encoder(autoencoder_input))\n",
    "autoencoder = models.Model(autoencoder_input, autoencoder_output, name=\"autoencoder\")\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.fit(\n",
    "    x_train, x_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0238f6-50ee-4336-8096-387981161bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10  # mostra 10 immagini\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # immagini originali\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    # immagini ricostruite\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Reconstructed\")\n",
    "    plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "z_test  = encoder.predict(x_test)\n",
    "\n",
    "print (z_test)\n",
    "\n",
    "decoded = decoder.predict(z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e0b3b",
   "metadata": {},
   "source": [
    "## Exercise 3: Autoencoder on real gravitational data with and without convolution layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc6874-3655-4263-9118-a8315ec62afe",
   "metadata": {},
   "source": [
    "The final exercise consists of creating two autoencoders—one with convolutional layers and one without—to compress and decompress data from a gravitational wave detector of the IGWN collaboration (Virgo and LIGO). To access and download a Gravitational Wave sample, you will have to use `gwosc`library:\n",
    "\n",
    "```\n",
    "!pip install gwosc\n",
    "\n",
    "from gwosc.datasets import event_gps\n",
    "from gwosc import datasets\n",
    "from gwpy.timeseries import TimeSeries\n",
    "\n",
    "import h5py\n",
    "gws=datasets.find_datasets(detector=\"L1\")\n",
    "gws_filtered = [s for s in gws if s.startswith((\"GW1\", \"GW2\"))]\n",
    "for el in gws_filtered:\n",
    "    print(el)\n",
    "    gps = event_gps(el)\n",
    "    start = int(gps) - 16   # seconds before\n",
    "    end = int(gps) + 16     # seconds aftes\n",
    "    data = TimeSeries.fetch_open_data('L1', start, end)\n",
    "    with h5py.File( save_dir+el+'.h5', 'w') as f:\n",
    "        f.create_dataset('data', data=data)\n",
    "```\n",
    "\n",
    "For this exercise **the data have already been downloaded** to the directory `/data/input_data/AI_INFN/gwdata` in Timeseries format and can be loaded into memory using the gwpy library:\n",
    "```\n",
    "all_files = [f for f in os.listdir(data_dir) if f.endswith(\".hdf5\")]\n",
    "files_to_load = all_files[:NFILES]\n",
    "time_series_list = []\n",
    "counter=0\n",
    "for fname in files_to_load:\n",
    "    counter=counter+1\n",
    "    path = os.path.join(data_dir, fname)\n",
    "    #print(f\"Carico {path} ...\")\n",
    "    ts = TimeSeries.read(path)\n",
    "    array = np.array(ts)\n",
    "    splitted = np.split(array, NSAMPLES)\n",
    "    time_series_list.extend(splitted)\n",
    "chunks = np.stack(time_series_list)\n",
    "chunks = chunks[..., np.newaxis]  # shape: (dim_split, NSAMPLES, 1)\n",
    "```\n",
    "with:\n",
    "- NFILES: number of files to load (100 will be enough)\n",
    "- NSAMPLES: number of chunks into which each file must be divided (start with 32).\n",
    "\n",
    "Each file represents a 32-second sequence sampled at 4096 Hz, hence each chunk will contain 4096 elements (1 second). We will create NSAMPLES chunks of (4096 * 32 / NSAMPLES) elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac69a971-c070-4316-917c-302e861b444a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gwpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3558b04b-4236-4ee8-8f92-2d230b7959ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, TimeDistributed, Flatten, Reshape, Input, Conv1D, Conv1DTranspose, Activation, InputLayer\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Nadam, Adam, SGD\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "from gwpy.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1443ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_dir=\"/data/input_data/AI_INFN/gwdata\"\n",
    "#data_dir=\"/home/mcorosu/gwdata\"\n",
    "\n",
    "NSAMPLES=32\n",
    "NFILES=100\n",
    "FREQ=4096\n",
    "SECS=32\n",
    "\n",
    "total_points_single = SECS*FREQ\n",
    "total_points = NFILES*total_points_single\n",
    "WINDOWSIZE = int(total_points_single / NSAMPLES)\n",
    "dim_split = total_points / WINDOWSIZE\n",
    "print (f'Number of input points: {WINDOWSIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9c1e4-fa0b-4e0f-8062-e5e9537c0d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## READING FILES\n",
    "all_files = [f for f in os.listdir(data_dir) if f.endswith(\".hdf5\")]\n",
    "files_to_load = all_files[:NFILES]\n",
    "time_series_list = []\n",
    "counter=0\n",
    "for fname in files_to_load:\n",
    "    counter=counter+1\n",
    "    path = os.path.join(data_dir, fname)\n",
    "    #print(f\"Carico {path} ...\")\n",
    "    ts = TimeSeries.read(path)\n",
    "    array = np.array(ts)\n",
    "    splitted = np.split(array, NSAMPLES)\n",
    "    time_series_list.extend(splitted)\n",
    "chunks = np.stack(time_series_list)\n",
    "chunks = chunks[..., np.newaxis]  # shape: (dim_split, NSAMPLES, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b740bb7-eadf-4236-93ca-b433669e84ae",
   "metadata": {},
   "source": [
    "\n",
    "For the autoencoders we will develop, we will use the hyperbolic tangent activation function, which has a range between -1 and 1. Therefore, we need to normalize our data values accordingly:\n",
    "```\n",
    "X_min = chunks.min(axis=1, keepdims=True)\n",
    "X_max = chunks.max(axis=1, keepdims=True)\n",
    "chunks_norm = 2 * (chunks - X_min) / (X_max - X_min) - 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f209d-4d57-468b-b6f8-366e40a73c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NORMALIZATION\n",
    "\n",
    "X_min = chunks.min(axis=1, keepdims=True)\n",
    "X_max = chunks.max(axis=1, keepdims=True)\n",
    "chunks_norm = 2 * (chunks - X_min) / (X_max - X_min) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11988517-393b-494f-8b12-829a036b31db",
   "metadata": {},
   "source": [
    "### Autoencoder model without convolution layers\n",
    "\n",
    "Now build an autoencoder with 4 Dense layers — two for encoding and two for decoding. Split each file in 32 chunks, each of 1 second (4096 elements)\n",
    "```\n",
    "original (size 4096) -> flatten -> encoded size 512 ->  encoded size 16 -> decoded size 32 -> decoded size original\n",
    "```\n",
    "Split the network so that you can extract and plot the encoded result. The encoding output dimension should be 64. Note that you have to first flatten the input chunks, as we have no convolution layer in your model:\n",
    "```\n",
    "encoder.add(Flatten(input_shape=(input_dim, 1)))\n",
    "```\n",
    "---\n",
    "\n",
    "#### Input\n",
    "\n",
    "- `Input(shape=(input_dim, 1))`  \n",
    "  The input signal is a 1D vector of length `input_dim`.  \n",
    "  It is first **flattened** to prepare it for the fully connected layers.\n",
    "\n",
    "---\n",
    "\n",
    "#### Encoder\n",
    "\n",
    "- **Flatten**  \n",
    "  Converts the 1D input of shape `(input_dim, 1)` into a flat vector of size `input_dim`.\n",
    "\n",
    "- **Dense(_num_neuroni, activation='tanh')**  \n",
    "  The first encoding layer learns a non-linear transformation of the input.  \n",
    "  Regularization (`l1_l2`) can be applied to both kernel and bias terms through the parameters `bias1`, `bias2`, `ker1`, and `ker2`.\n",
    "\n",
    "- **Dense(_latent_dim, activation='tanh')**  \n",
    "  This is the **latent (bottleneck) layer**, where the model compresses the information into a lower-dimensional representation of size `_latent_dim`.\n",
    "\n",
    "---\n",
    "\n",
    "#### Decoder\n",
    "\n",
    "- **Dense(_num_neuroni, activation='tanh')**  \n",
    "  The decoder begins reconstructing the signal from the latent representation.\n",
    "\n",
    "- **Dense(input_dim, activation='tanh')**  \n",
    "  Reconstructs the signal back to its original dimension.\n",
    "\n",
    "- **Reshape((input_dim, 1))**  \n",
    "  Reshapes the output to match the input format.\n",
    "\n",
    "---\n",
    "\n",
    "#### Model Compilation\n",
    "\n",
    "- **Loss:** `mse` (Mean Squared Error)  \n",
    "  Measures how close the reconstructed output is to the input.\n",
    "\n",
    "- **Optimizer:** `Adam(learning_rate=1e-4)`  \n",
    "  Adaptive learning rate optimizer for stable convergence.\n",
    "\n",
    "- **Metrics:** `mse`  \n",
    "  Tracks the reconstruction error during training.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601e565-ba6a-4b84-91c3-297807db6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri autoencoder\n",
    "input_dim = WINDOWSIZE\n",
    "latent_dim = 64\n",
    "epochs=50\n",
    "num_neuroni=512\n",
    "dropout=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ab918-0292-44d4-bdad-cf8b17567c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder with dense leyers only\n",
    "def autoencoder_model(input_dim=128, _num_neuroni=64, _latent_dim=16, _dropout=0, bias1=0, bias2=0, ker1=0, ker2=0):\n",
    "\n",
    "    # input layer\n",
    "    input_signal = Input(shape=(input_dim, 1))\n",
    "    \n",
    "    encoder = Sequential()\n",
    "\n",
    "    # flatten\n",
    "    encoder.add(Flatten(input_shape=(input_dim, 1)))\n",
    "    \n",
    "    # encoding\n",
    "    encoder.add(Dense(_num_neuroni, activation='tanh', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "  \n",
    "    # latent layer\n",
    "    encoder.add(Dense(_latent_dim, activation='tanh', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "\n",
    "    decoder = Sequential()\n",
    "    \n",
    "    # decoding\n",
    "    decoder.add(Dense(_num_neuroni, activation='tanh', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    decoder.add(Dense(input_dim, activation='tanh', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    \n",
    "    # reshape\n",
    "    decoder.add(Reshape((input_dim, 1)))\n",
    "\n",
    "    # compile it\n",
    "    # compile it\n",
    "    encoded = encoder(input_signal)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = Model(inputs=input_signal, outputs=decoded)\n",
    "    autoencoder.compile(optimizer=Adam(learning_rate=1e-4), loss='mse', metrics=['mse'])\n",
    "    return autoencoder, decoder, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f5fb07-42bf-4886-b4cb-9e0364014ccf",
   "metadata": {},
   "source": [
    "### Autoencoder model with convolution layers\n",
    "\n",
    "Finally  build an autoencoder with 3 Conv1D layers and one Dense  for encoding. Split the network so that you can extract and plot the encoding result.\n",
    "As before, the input data dimension is 4096 \n",
    "\n",
    "---\n",
    "\n",
    "####  Input\n",
    "\n",
    "- `Input(shape=(input_dim, 1))`  \n",
    "  The input signal is a 1D vector (e.g., a signal or time series) of length `input_dim`.\n",
    "\n",
    "---\n",
    "\n",
    "####  Encoder\n",
    "\n",
    "- **Conv1D (3 layers)**  \n",
    "  Applies convolutional filters to extract local features from the signal, progressively reducing its dimensionality via `strides=2`.  \n",
    "  Uses the `tanh` activation function to introduce non-linearity.\n",
    "\n",
    "- **Flatten**  \n",
    "  Converts the 3D tensor into a 1D vector.\n",
    "\n",
    "- **Dense(_latent_dim)**  \n",
    "  Compresses the information into a **latent code** of size `_latent_dim`.  \n",
    "  This is the compact representation of the input signal.\n",
    "\n",
    "---\n",
    "\n",
    "####  Decoder\n",
    "\n",
    "- **Dense(input_dim // 8 * 64)**  \n",
    "  Expands the latent code to match the encoder’s output shape.\n",
    "\n",
    "- **Reshape((input_dim // 8, 64))**  \n",
    "  Reshapes the vector into a 3D tensor suitable for transposed convolutions.\n",
    "\n",
    "- **Conv1DTranspose (3 layers)**  \n",
    "  Performs the inverse of convolution — progressively upsampling the signal.  \n",
    "  The first two layers reconstruct intermediate features, and the last one generates the final output.\n",
    "\n",
    "- **Activation('tanh')**  \n",
    "  Ensures that the reconstructed signal lies within the same range as the input.\n",
    "\n",
    "---\n",
    "\n",
    "####  Model Compilation\n",
    "\n",
    "- **Loss:** `mse` (Mean Squared Error)  \n",
    "  Measures the difference between input and reconstructed output.\n",
    "\n",
    "- **Optimizer:** `adam`  \n",
    "  Adaptive optimizer ensuring efficient convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6d87e-4355-4b64-85aa-a1131242aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder with convolution layer\n",
    "def autoencoder_conv_model(input_dim=128, _num_neuroni=64, _latent_dim=16, _dropout=0, bias1=0, bias2=0, ker1=0, ker2=0):\n",
    "\n",
    "    # input layer\n",
    "    input_signal = Input(shape=(input_dim, 1))\n",
    "    \n",
    "    # Encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(input_shape=(input_dim, 1)))\n",
    "    encoder.add(Conv1D(16, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
    "    encoder.add(Conv1D(32, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
    "    encoder.add(Conv1D(64, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(_latent_dim, activation='tanh'))\n",
    "\n",
    "    # Decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer(input_shape=(_latent_dim,)))\n",
    "    decoder.add(Dense(input_dim // 8 * 64, activation='tanh'))  # deve corrispondere alla forma finale dell'encoder\n",
    "    decoder.add(Reshape((input_dim // 8, 64)))\n",
    "    decoder.add(Conv1DTranspose(32, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
    "    decoder.add(Conv1DTranspose(16, kernel_size=5, strides=2, padding='same', activation='tanh'))\n",
    "    decoder.add(Conv1DTranspose(1, kernel_size=5, strides=2, padding='same'))\n",
    "    decoder.add(Activation('tanh'))\n",
    "\n",
    "    # compile it\n",
    "    encoded = encoder(input_signal)\n",
    "    decoded = decoder(encoded)\n",
    "    autoencoder = Model(inputs=input_signal, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    return autoencoder, decoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a642b1a-2bde-49d9-bca9-3503e12b025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  MACRO ###\n",
    "USECONV=True          ## USE CONVOLUTION\n",
    "##############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e6e9b-d25b-4c48-9b97-6712b7be088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USECONV == True:\n",
    "    (autoencoder, decoder, encoder) = autoencoder_conv_model(input_dim=input_dim, _num_neuroni=num_neuroni, _latent_dim=latent_dim, _dropout=dropout, bias1=0.3, bias2=0.3, ker1=0, ker2=0)\n",
    "else:\n",
    "    (autoencoder, decoder, encoder) = autoencoder_model(input_dim=input_dim, _num_neuroni=num_neuroni, _latent_dim=latent_dim, _dropout=dropout, bias1=0.3, bias2=0.3, ker1=0, ker2=0)\n",
    "# Riepilogo\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d840f93a-ad1e-4187-a1d8-3d759a2f68f1",
   "metadata": {},
   "source": [
    "### Training and plotting results\n",
    "\n",
    "Train your models splitting the data in 90% training and 10% validation using `validation_split=0.1`  and plot \"the training vs validation loss\" graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1f3ef-bee7-400b-bd05-3be5bba340b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TRAINING\n",
    "history = autoencoder.fit(chunks_norm, chunks_norm, epochs=epochs, batch_size=32, shuffle=True, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de5898b-5ebc-4fdf-bd4e-e50bc8911a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PLOT\n",
    "loss = history.history['loss']        # lista con la loss di training per ogni epoca\n",
    "val_loss = history.history['val_loss'] # lista con la loss di validazione per ogni epoca\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "#output = autoencoder.predict(chunks_norm)\n",
    "output = encoder.predict(chunks_norm)\n",
    "\n",
    "numero=11\n",
    "fig, axes = plt.subplots(5, 2)\n",
    "row, col = 0, 0\n",
    "for el in range(1,numero):\n",
    "    #axes[row,col].plot(chunks_norm[el].flatten())\n",
    "    axes[row,col].plot(output[el].flatten())\n",
    "    \n",
    "    if el % 2 == 1:  # dispari → vai alla colonna successiva\n",
    "        col += 1\n",
    "    else:           # pari → vai alla riga successiva e reset colonna\n",
    "        row += 1\n",
    "        col = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0c25b-d83d-43fa-a8e6-799b15e4f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dim = 128\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 4.0, assuming the input is 128 floats\n",
    "encoding_dim_1 = 16  # 16 floats -> compression of factor 8.0, assuming the input is 128 floats\n",
    "\n",
    "noise = np.random.normal(0, 3, original_dim*1000)\n",
    "X_signal = noise.reshape((1000, original_dim))\n",
    "x_train = X_signal[0:900,:]\n",
    "x_test = X_signal[900:,:]\n",
    "\n",
    "\n",
    "# a very simple model, feedforward neural network with two layers and with two different activation functions\n",
    "def baseline_model(learning_rate=5e-6, activation='sigmoid', bias1=1e-9, bias2=1e-9, ker1=1e-9, ker2=1e-9):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(original_dim,)))\n",
    "    model.add(Dense(encoding_dim, activation=activation, bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    model.add(Dense(original_dim, activation='relu', bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2)))\n",
    "    \n",
    "    model.compile(optimizer=Nadam(learning_rate=learning_rate), loss='mse', metrics=['mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "X_signal_1 = noise.reshape((1000, original_dim, 1))\n",
    "x_train_1 = X_signal_1[0:900,:,:]\n",
    "x_test_1 = X_signal_1[900:,:,:]\n",
    "\n",
    "def simple_model(bias1=0, bias2=0, ker1=0, ker2=0):\n",
    "    # This is our input image\n",
    "    input_signal = keras.Input(shape=(original_dim,1))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    convolved = layers.Conv1D(64, kernel_size=3, strides=1, padding='causal' , activation='relu')(input_signal)\n",
    "    flatted = layers.Flatten()(convolved)\n",
    "    encoded = layers.Dense(encoding_dim, activation='relu',bias_regularizer=regularizers.l1_l2(l1=bias1, l2=bias2), kernel_regularizer=regularizers.l1_l2(l1=ker1, l2=ker2))(flatted)\n",
    "    encoded_1 = layers.Dense(encoding_dim_1, activation='relu')(encoded)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded_1 = layers.Dense(encoding_dim, activation='sigmoid')(encoded_1)\n",
    "    decoded = layers.Dense(original_dim, activation='sigmoid')(decoded_1)\n",
    "    decoded = layers.Reshape((original_dim,1))(decoded)\n",
    "    # This model maps an input to its reconstruction\n",
    "    autoencoder = keras.Model(input_signal, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mse', metrics=['mse'])\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "autoenc=simple_model()\n",
    "autoenc.fit(x_train_1,x_train_1, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e4c95-f994-4a40-bc98-b031e6c49b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
