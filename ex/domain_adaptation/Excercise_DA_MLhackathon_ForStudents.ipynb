{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d729525-b394-4876-95ae-f8744a0cc093",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# **Domain Adaptation to train model-independent classifiers in High Energy Physics**\n",
    "\n",
    "Training Machine Learning classifiers to distinguish signal from background in High Energy Physics is usually based on simulated datasets, at least for the signal component. The simulation of signal relies on theoretical models that often include hypotheses that have not been completely validated, yet. As a consequence, an implicit bias is introduced in the classifier performance that will differ from model to model.\n",
    "\n",
    "Domain adaptation can be used to mitigate the dependence of the trained classifier on the theoretical model adopted for training, forcing the classifier Neural Network to actively ignore the information necessary to distinguish different theoretical models.\n",
    "\n",
    "In this exercise, which is inspired by a recently published study ([EPJC 82 (2022)](https://link.springer.com/article/10.1140/epjc/s10052-022-10871-3), [arXiv:2207.09293](https://arxiv.org/abs/2207.09293)), we will implement a simplified version of the method to simulated LHC datasets, discussing the most interesting features and pitfalls of the method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e41ff6-b2e5-4f7f-8d2d-2037548afba4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Brief description of the physics use case\n",
    "\n",
    "We consider the physics use case of a cross section measurement at the LHC. In particular the process we are interested to measure is the Higgs boson produced through *Vector Boson Fusion* (**VBF**) and decaying to a pair of W bosons. The final state of interest is the fully leptonic one, i.e. when both W bosons decay to leptons $W^\\pm\\to\\ell^\\pm\\nu$.\n",
    "\n",
    "The Feynman diagram for the signal process is depicted below:\n",
    "\n",
    "<img src=\"http://lviliani.web.cern.ch/lviliani/FiguresForDANotebook/vbf.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "This is a rare process and the usage of Machine Learning techniques for the event classification and discrimination from backgrounds is extremely important. In this use case we consider two distinct sources of background processes: the Higgs boson production through gluon fusion and consequent decay to $WW\\to2\\ell2\\nu$ (**ggH**), and all other sources of backgrounds (**BKG**), mainly arising from $t\\bar{t}$ and non-resonant $WW$ production. Examples of the Feynman diagrams for ggH (left), $t\\bar{t}$ (center) and $WW$ (right) processes are shown below.\n",
    "\n",
    "<img src=\"http://lviliani.web.cern.ch/lviliani/FiguresForDANotebook/ggH.png\" width=\"400\" height=\"400\" /> <img src=\"http://lviliani.web.cern.ch/lviliani/FiguresForDANotebook/ttbar.png\" width=\"400\" height=\"400\" /> <img  src=\"http://lviliani.web.cern.ch/lviliani/FiguresForDANotebook/WW.png\" width=\"400\" height=\"400\" /> \n",
    "\n",
    "We want to build a three-classes feed-forward Deep Neural Network to categorize the events in the VBF, ggH and BKG classes with the maximum achievable accuracy. At the same time, we want the output probability distributions to be independent of the particular VBF theoretical model used in the training and in the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306bd8a5-356b-42ee-b8e5-9e6a65ba159b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load, read and understand the data\n",
    "\n",
    "Let's start the hackathon by reading the dataset and understanding what we will work with.\n",
    "\n",
    "The dataset has been already pre-processed and is provided as a *pandas* dataframe saved in a *pickle* file.\n",
    "It can be loaded easily using the pandas `read_pickle` function as follows.\n",
    "\n",
    "Let's read and print to screen the dataframe content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb55a5-7c68-4f7c-8035-631cb54246ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# IF USING COLAB, Uncomment and run the next lines and comment the next block; OTHERWISE leave all as is\n",
    "#%pip install pickle5\n",
    "#import pickle5 as pickle\n",
    "#!rm -f dataset_DA.pkl\n",
    "#!wget https://pandora.infn.it/public/488317/dl/dataset_DA.pkl\n",
    "#with open('dataset_DA.pkl', \"rb\") as fh:\n",
    "#  df = pickle.load(fh)\n",
    "# END COLAB BLOCK\n",
    "\n",
    "\n",
    "# IF NOT USING COLAB, please use the standard code below\n",
    "df = pd.read_pickle('https://pandora.infn.it/public/488317/dl/dataset_DA.pkl')\n",
    "# END NON COLAB BLOCK\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c305d0-ceef-4eb7-b27e-455a39f43e91",
   "metadata": {},
   "source": [
    "The dataframe contains a total of ~60k events. \n",
    "\n",
    "The first 24 columns contain the input features that we will use in our DNN architecture.\n",
    "Although the physical meaning of all the variables is not important to understand this excercise, we still report below a brief description of each one for reference.\n",
    "\n",
    "In general, they are high-level variables regarding leptons and jets kinematics that are known to be powerful for the discrimination of signal and background processes.\n",
    "\n",
    "- `ptj1` and `ptj2`: the magnitudes of the transverse momenta of the leading and subleading jet;\n",
    "- `etaj1` and `etaj2`: the pseudorapidity of the leading and subleading jet. Jets arising from VBF processes tend to be emitted at larger pseudorapidity with respect to background events;\n",
    "- `detajj`: the separation in pseudorapidity between the two leading jets in the final state. The signal shows a larger pseudorapidity gap with respect to the backgrounds;\n",
    "- `mjj`: the invariant mass of the dijet system. It has a good discrimination power since it is typically larger for the signal than for the background;\n",
    "- `ptll`, `ptl1`, `ptl2`: the magnitudes of the transverse momenta of the dilepton system, the leading lepton, and the subleading lepton, respectively;\n",
    "- `etal1` and `etal2`: the pseudorapidity of the leading and subleading lepton, respectively;\n",
    "- `mll`: the invariant mass of the lepton pair. Due to the spin correlation effect in the $H\\to WW\\to2\\ell2\\nu$ decay chain, this variable is peaked at low values for the VBF and ggH mechanisms, while showing a broadened shape for non-resonant events;\n",
    "- `dphill`: the angular separation in $\\phi$ between the two leptons;\n",
    "- `drll`: the radial separation between the two leptons;\n",
    "- `mlj(...)`: the invariant mass of the system consisting of the i-th lepton and j-th jet (all four permutations are considered);\n",
    "- `ctot`: $Ctot = \\log ( \\sum_\\ell (2\\eta_\\ell - \\sum_j \\eta_j) / |\\Delta\\eta_{jj}|)$ is called centrality of the dilepton system;\n",
    "- `met`: the missing transverse energy in the event;\n",
    "- `mth`: the transverse mass of the system computed as $m_T^H = \\sqrt{2 p_T^{\\ell\\ell}p_T^{miss} \\cos(\\Delta\\phi(p_T^{\\ell\\ell},p_T^{miss}))}$;\n",
    "- `mti`: the visible mass computed as $m_T^{vis} = \\sqrt{ (p^{\\ell\\ell} + p_T^{miss})^2 - (\\vec{p}^{\\ell\\ell} + \\vec{p}_T^{miss})^2 }$\n",
    "- `dphillmet`: the azimuthal opening angle between the dilepton system and MET, i.e. $\\Delta\\phi(p_T^{\\ell\\ell},p_T^{miss})$\n",
    "- `ht`: the scalar sum of the transverse momenta of all jets in the event.\n",
    "\n",
    "The remaining columns in the dataframe represent the labels that identify each process:\n",
    "- `isVBF`: = 1 for VBF (either SM or BSM) events;\n",
    "- `isBKG`: = 1 for background events;\n",
    "- `isGGH`: = 1 for gluon fusion events;\n",
    "- `isSM`: = 1 for SM VBF events;\n",
    "- `isBSM{i}`: we included six (i = 0,...,5) different BSM models in the dataset, corresponding to various anomalous couplings of the Higgs boson with vector bosons.\n",
    "\n",
    "The first three labels identify our **source domain ($\\mathcal{S}$)**, while the latters identify the **target domain ($\\mathcal{T}$)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00cefb2-3e52-4686-96cd-1ea7e0b6bb66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How many events of each kind do we have?\n",
    "\n",
    "Let's know check how many events of each process we have in our dataset. In this case we opted for a balanced dataset composed by **VBF**, **ggH** and **BKG** processes in equal proportions.\n",
    "\n",
    "Note that the data labelled as `isVBF` are composed in equal proportions of the different VBF models. In our dataset we have $2828$ events for each VBF model (either the SM and the 6 BSM models), for a total of $2828 \\cdot 6 = 19796$ `isVBF` events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee14f2-2182-4eac-9b37-98a6c7ea17f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in df.columns[24:35]:\n",
    "    print (col, len(df[df[col]==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723adec6-7f04-428f-89ac-528bb1d54000",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare input features for the various processes\n",
    "\n",
    "Let's have a deeper look at our dataset by plotting the distributions of all the input features for VBF, ggH and BKG events.\n",
    "\n",
    "What are the most discriminating features (by eye)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def9e0f2-a8e5-4ada-9e83-ff8295854d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "# List of features - the first 24 columns of our dataset\n",
    "features = df.columns[:24]\n",
    "# VBF, ggH and BKG labels\n",
    "labels = df.columns[24:27]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8043c385-4a67-4453-bb83-f2a920697217",
   "metadata": {},
   "source": [
    "**YOUR TURN: Plot the distributions of each feature comparing the VBF, ggH and BKG labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3090b575-8cc3-4b13-abad-1db1f70b7a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d77f7a-04ec-4e96-831b-c445a214b785",
   "metadata": {},
   "source": [
    "Let's now plot the distributions of the input features comnparing the various VBF models.\n",
    "\n",
    "Do you spot any particular feature that is significantly different for the different models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f087d835-0e80-4a87-a339-1d79e4b53a5b",
   "metadata": {},
   "source": [
    "**YOUR TURN: Plot the distributions of each feature comparing the isSM, isBSM0, ..., isBSM5 labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6165e28-ee46-4dd8-8d7b-5f50f8682861",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ceded6-6d1f-49e1-9541-29175b33a2ba",
   "metadata": {},
   "source": [
    "The simplest way to achieve our goal, i.e. have a good discrimination among VBF, ggH and BKG, but at the same time being independent of the different VBF models, would be to drop the features that are sensitive to the VBF modelling but do not provide a significant discrimination among VBF, ggH and BKG.\n",
    "\n",
    "But this is not always possible (as in the current use case), because some of the features that are good for the classification might also be good for distinguishing different models. Dropping those would mean a huge loss of classification power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de953a2-333c-4832-abb4-9d7bec617ac0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Define the Domain Adaptation model\n",
    "\n",
    "In order to achieve our goal we will adopt a particular flavor of Domain Adaptation, whose objective is to find a common representation for the source and target domains.\n",
    "\n",
    "We want to build our Domain Adaptation model according to an Adversarial Deep Neural Network approach (also known as domain adversarial training), according to the following scheme:\n",
    "<img src=\"http://lviliani.web.cern.ch/lviliani/FiguresForDANotebook/ADNN.png\" width=\"800\" height=\"800\" />\n",
    "\n",
    "The main components of the ADNN are:\n",
    "- the *Classifier (C)*: a feed-forward Deep Neural Network with the goal to classify events in 3 classes (VBF signal, ggH and BKG);\n",
    "- the *Adversary (A)*: a feed-forward Deep Neural Network connected to the second-to-last layer of C (representation) with the goal to classify different signal models.\n",
    "\n",
    "*C* and *A* are trained in a competitive way with the final goal of maximizing the performance of *C* but simultaneously preventing *A* to identify the alternative signal models.\n",
    "Schematically, the loss function we want to minimize is defined as follows:\n",
    "\n",
    "<img src=\"http://lviliani.web.cern.ch/lviliani/FiguresForDANotebook/loss.png\" width=\"400\" height=\"400\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff34d81-f5d6-4f06-9908-7b3f44acd4f5",
   "metadata": {},
   "source": [
    "We start by importing the relevant packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e1568-6ab2-44f6-932c-22bfcef6abf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "from tensorflow.python.client import device_lib\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81737080-22a6-4ca5-9c16-752ddaae3fef",
   "metadata": {},
   "source": [
    "Define the `NeuralNetworkWithDomainAdaptation` class as inherting from `tf.Module`. Define an `__init__` function that initializes the relevant class variables and calls the `build` function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a634b2c1-8f0d-4ec7-931e-99f77189fb6e",
   "metadata": {},
   "source": [
    "In the `build` function we define the structure of the model and we return the model weigths.\n",
    "\n",
    "We define 3 Keras Sequential models:\n",
    "- `model1` is the classifier network without the last output layer, i.e. the second-to-last layer is a representation of the input features;\n",
    "- `model2` is the adversary network, connected to the second-to-last layer of `model1`;\n",
    "- `model3` is just the output layer of the classifier that applies a softmax activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d575841-964e-4948-a0f3-13d75e7fee84",
   "metadata": {},
   "source": [
    "In the `fit` function we implement the epochs loop and we keep track of the classifier, adversary and total loss functions.\n",
    "\n",
    "Note that we implemented a Batch Gradient Descent approach (gradients computed and weights updated every epoch using the full data), in which we call the `_train` function every epoch. A Mini-batch Gradient Descent approach can be easily implemented by splitting the training data in smaller batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608b2b4-802a-422f-a415-e043883bdd32",
   "metadata": {},
   "source": [
    "The `_train` function contains the custom training strategy, implementing the C and A loss functions using the Categorical Cross Entropy Keras loss. In this function we compute the gradients of the loss functions and update the weights.\n",
    "\n",
    "Take your time to look carefully at the loss definition and understand the gradients. Note that:\n",
    "\n",
    "- we first compute the gradient of the total loss L(C+A) with respect to the classifier weights;\n",
    "- then we compute the gradient of the adversary loss L(A) with respect to the adversary weights;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c69fdcc-9832-4191-b5c6-4fad814dea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkWithDomainAdaptation ( tf.Module ):\n",
    "    \n",
    "    def __init__ (self, nEpochs, learning_rate1, learning_rate2, alpha, N_NODES, n_layers1, n_layers2, n_features, n_outputsC=3, n_outputsA=7):\n",
    "        self.learning_rate1 = learning_rate1\n",
    "        self.learning_rate2 = learning_rate2\n",
    "        self.optimizer  = tf.optimizers.Adam (self.learning_rate1)\n",
    "        self.optimizer2 = tf.optimizers.Adam (self.learning_rate2)\n",
    "        self.nEpochs = nEpochs\n",
    "        self.alpha = alpha\n",
    "        self.N_NODES = N_NODES\n",
    "        self.n_layers1 = n_layers1\n",
    "        self.n_layers2 = n_layers2\n",
    "        self.n_features = n_features\n",
    "        self.n_outputsC = n_outputsC\n",
    "        self.n_outputsA = n_outputsA\n",
    "        self.weightsC, self.weightsA = self.build (self.n_features, self.N_NODES)\n",
    "\n",
    "    # Define the structure of the model\n",
    "    def build (self, n_input, N_NODES):\n",
    "        # initializer = initializers.Ones()\n",
    "\n",
    "        # Feature representation (i.e. classifier w/o the last layer)\n",
    "        self.model1 = Sequential()\n",
    "        self.model1.add(Dense (self.N_NODES, activation = 'relu', input_dim  = n_input))\n",
    "        for i in range(self.n_layers1):\n",
    "            self.model1.add(Dense (self.N_NODES, activation = 'relu'))\n",
    "\n",
    "        # Adversary model\n",
    "        \n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        ### HINT: implement the adversary model (model2) similarly to what was done for model1\n",
    "        ### In this case the input will be the last layer of the feature extractor.\n",
    "        ### Also, you should add one last layer where a softmax activation is applied.\n",
    "\n",
    "        # Classifier output (just the last layer of C)\n",
    "        self.model3 = Sequential()\n",
    "        self.model3.add(Dense (self.n_outputsC, activation = 'softmax',input_dim = self.N_NODES))      \n",
    "        \n",
    "        return (self.model1.weights + self.model3.weights, self.model2.weights)\n",
    "\n",
    "    # Performs the epochs loop and the actual training.\n",
    "    # Monitors the training and validation loss functions, both for the classifier and the adversary.\n",
    "    # Returns the classifier categorical accuracy.\n",
    "    def fit (self, X, Y, Y_adv, X_val, Y_val, Y_adv_val, show_loss = False):\n",
    "        # The following lists will contain the values of the loss functions in each epoch\n",
    "        losses = [] # overall loss container\n",
    "        losses_adv = [] # adversary loss container\n",
    "        losses_cl = [] # classifier loss container\n",
    "\n",
    "        # Same for the \"validation\" losses\n",
    "        losses_val = []\n",
    "        losses_adv_val = []\n",
    "        losses_cl_val = []\n",
    "\n",
    "        # Compute means and sigmas for the input feature pre-processing\n",
    "        self.means = np.mean ( X, axis = 0)\n",
    "        self.sigmas = np.std ( X, axis = 0)\n",
    "\n",
    "        ######################\n",
    "        ### YOUR CODE HERE ###\n",
    "        ######################\n",
    "        ### HINT: implement the loop over the number of epochs (self.nEpochs) by hand\n",
    "        ### In each iteration call the self._train function (see below) and store the loss values in the containers\n",
    "\n",
    "        losses = np.array(losses)\n",
    "        losses_adv = np.array(losses_adv)\n",
    "        losses_cl = np.array(losses_cl)\n",
    "               \n",
    "        losses_val = np.array(losses_val)\n",
    "        losses_adv_val = np.array(losses_adv_val)\n",
    "        losses_cl_val = np.array(losses_cl_val)\n",
    "               \n",
    "        plt.plot (losses_adv, color = \"y\", label='Training set')\n",
    "        plt.plot (losses_adv_val, color ='orange', label = \"Validation set\")\n",
    "        plt.xlabel (\"Epoch\"); plt.ylabel (\"Loss(A)\")\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot (losses_cl, color='r', label='Training set')\n",
    "        plt.plot (losses_cl_val, color='darkred', label='Validation set')\n",
    "        plt.xlabel (\"Epoch\"); plt.ylabel (\"Loss(C)\")\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.plot (losses, color='c', label='Training set')\n",
    "        plt.plot (losses_val, color='tab:blue', label='Validation set')\n",
    "        plt.xlabel (\"Epoch\"); plt.ylabel (\"Loss(C+A)\")\n",
    "        plt.legend(frameon=False)\n",
    "        plt.show()\n",
    "        \n",
    "        ca = tf.keras.metrics.CategoricalAccuracy()\n",
    "        ca.update_state(Y, self.predict_proba(X))\n",
    "        \n",
    "        return ca.result().numpy()\n",
    "\n",
    "    # Applies a pre-processing to the input features and returns the classifier representation.\n",
    "    @tf.function\n",
    "    def representation (self, X):\n",
    "        ppX = (X - self.means)/self.sigmas\n",
    "        return  self.model1 (ppX) \n",
    "\n",
    "    # Returns the classifier output\n",
    "    #@tf.function\n",
    "    def predict_proba (self, X):\n",
    "        ppX2 = self.representation (X)\n",
    "        return tf.clip_by_value ( self.model3 (ppX2), 1e-7, 1. - 1e-7 )\n",
    "\n",
    "    # Returns the adversary output\n",
    "    #@tf.function\n",
    "    def predict_proba_adv (self, X):\n",
    "        ppX2 = self.representation (X)\n",
    "        return tf.clip_by_value ( self.model2 (ppX2), 1e-7, 1. - 1e-7 )\n",
    "\n",
    "    @tf.function\n",
    "    def _train (self, X, Y, Y_adv, X_val, Y_val, Y_adv_val):\n",
    "        Y_true = tf.cast (Y, tf.float32)\n",
    "        Y_true_val = tf.cast (Y_val, tf.float32)\n",
    "        \n",
    "        Y_true_adv = tf.cast (Y_adv, tf.float32)\n",
    "        Y_true_adv_val = tf.cast (Y_adv_val, tf.float32)\n",
    "\n",
    "        with tf.GradientTape() as gt, tf.GradientTape() as gt_adv:\n",
    "            #gt.watch ( self.weightsC )\n",
    "            Y_hat = self.predict_proba (X) #N3(N1(x))\n",
    "            Y_hat_adv = self.predict_proba_adv (X)\n",
    "            Y_hat_val = self.predict_proba (X_val) #N3(N1(x)) validation set\n",
    "            Y_hat_adv_val = self.predict_proba_adv (X_val)\n",
    "            \n",
    "            ## Training set\n",
    "            # Use the categorical cross-entropy as loss function for the adversary\n",
    "            cce_adv = tf.keras.losses.CategoricalCrossentropy()\n",
    "            \n",
    "            # Sums the contents of each row of the Y_true_adv tensor to get a 1D tensor with N_events length\n",
    "            # containing 0 if the event is not VBF or 1 if it is VBF (SM or BSM)\n",
    "            sum_adv = tf.math.reduce_sum(Y_true_adv, axis=1)\n",
    "            \n",
    "            # The second term in the multiplication is used to set the loss at 0 for non-VBF events\n",
    "            # i.e. the loss of the adversary is computed only for VBF (SM and BSM) events\n",
    "            loss_adv = tf.math.reduce_sum(( cce_adv( Y_true_adv, Y_hat_adv) )*( tf.cast( sum_adv.numpy()!=0, tf.float32 ) ))\n",
    "            \n",
    "            # Divide the loss for the total number of VBF (SM and BSM) events to get the average loss\n",
    "            loss_adv = loss_adv / tf.cast((tf.math.reduce_sum(sum_adv, axis=0)).numpy(),tf.float32 )\n",
    "            \n",
    "            # Use the categorical cross-entropy as loss function for the classifier\n",
    "            ######################\n",
    "            ### YOUR CODE HERE ###\n",
    "            ######################\n",
    "            \n",
    "            # The overall loss is L(C) - self.alpha*L(A)\n",
    "            ######################\n",
    "            ### YOUR CODE HERE ###\n",
    "            ######################\n",
    "            \n",
    "            ## Validation set\n",
    "            \n",
    "            ######################\n",
    "            ### YOUR CODE HERE ###\n",
    "            ######################\n",
    "            ### HINT: repeat the procedure above for the validation dataset\n",
    "            \n",
    "            # Compute the gradient of the overall loss with respect to the classifier weights\n",
    "            gradients = ### YOUR CODE HERE ### HINT: use the tf.GradientTape gradient function\n",
    "\n",
    "            # Then compute the gradient of L(A) with respect to the adversary weights\n",
    "            gradients_adv = ### YOUR CODE HERE ### HINT: use the tf.GradientTape gradient function\n",
    "\n",
    "        # Apply the gradients\n",
    "        self.optimizer.apply_gradients ( zip(gradients, self.weightsC) )\n",
    "        self.optimizer2.apply_gradients ( zip(gradients_adv, self.weightsA) )\n",
    "        \n",
    "        return loss, loss_adv, loss_cl, loss_val, loss_adv_val, loss_cl_val\n",
    "\n",
    "    # Some ancillary functions to save the model weights, reset the optimizers or set specific parameters.\n",
    "    def save_weights(self, model_name):\n",
    "        self.model1.save_weights(model_name+'_weights_1')\n",
    "        self.model2.save_weights(model_name+'_weights_2')\n",
    "        self.model3.save_weights(model_name+'_weights_3')\n",
    "    \n",
    "    def load_weights(self, model_name):\n",
    "        self.model1.load_weights(model_name+'_weights_1')\n",
    "        self.model2.load_weights(model_name+'_weights_2')\n",
    "        self.model3.load_weights(model_name+'_weights_3')\n",
    "        \n",
    "    def save_model(self, model_name):\n",
    "        self.model1.save(\"saved_models/\"+model_name+\"_1\")\n",
    "        self.model2.save(\"saved_models/\"+model_name+\"_2\")\n",
    "        self.model3.save(\"saved_models/\"+model_name+\"_3\")\n",
    "\n",
    "    def reset_optimizers(self):\n",
    "        self.optimizer  = tf.optimizers.Adam (self.learning_rate1)\n",
    "        self.optimizer2 = tf.optimizers.Adam (self.learning_rate2)\n",
    "        \n",
    "    def set_alpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def set_epochs(self, epochs):\n",
    "        self.nEpochs = epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefa974-ff1b-4b7f-9cec-fab1ad00e341",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Training of the ADNN model\n",
    "\n",
    "Now that we have defined the model structure, let's do the actual training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1543a3-3862-4f5b-b72f-dfe4bb6091b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Extract the input features and labels from the original dataset and split in training (80%) and validation (20%)\n",
    "\n",
    "First we split our data in 2 randomly chosen subsets: we will use the first one ($80\\%$ of the events) as training data, while the remaining smaller subset ($20\\%$ of the events) will be used for the validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906fb5f-22cd-49b3-a204-03b09e241786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NDIM = len(features)\n",
    "\n",
    "# Before doing the splitting, a random shuffle of the dataset doesn't hurt\n",
    "df = shuffle(df)\n",
    "\n",
    "# Perform the splitting and define training and validation datasets\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "df_train = df[msk]\n",
    "df_val = df[~msk]\n",
    "\n",
    "X = df_train.values[:,0:NDIM]\n",
    "Y = df_train.values[:,NDIM:NDIM+3] # isVBF, isGGH, isBKG\n",
    "Y_adv = df_train.values[:,NDIM+3:NDIM+10] # isSM, isBSM0, isBSM1, ..., isBSM5\n",
    "\n",
    "X_val = df_val.values[:,0:NDIM]\n",
    "Y_val = df_val.values[:,NDIM:NDIM+3] # isVBF, isGGH, isBKG\n",
    "Y_adv_val = df_val.values[:,NDIM+3:NDIM+10] # isSM, isBSM0, isBSM1, ..., isBSM5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cca561-115d-475d-97a8-c8c00a48adcf",
   "metadata": {},
   "source": [
    "## Build the ADNN model and define the needed parameters\n",
    "\n",
    "Let's instantiate our `NeuralNetworkWithDomainAdaptation` class with some standard hyperparameter values.\n",
    "\n",
    "Also, before starting the training, we want to save the initial model weights that we will reuse later in the optimization to restart every time from the same starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5842102f-5a82-4598-a1d9-15d43e3106a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nEpochs, learning_rate1, learning_rate2, alpha, N_NODES, n_layers1, n_layers2, n_features\n",
    "adnn = NeuralNetworkWithDomainAdaptation(500, learning_rate1=0.0001, learning_rate2=0.0001, alpha=0.1, N_NODES=50, n_layers1=5, n_layers2=5, n_features=X.shape[1])\n",
    "\n",
    "# Save initial set of weights (before training) to re-initialize the ADNN in later steps.\n",
    "# Useful if we want to restart always from the same starting point during the optimization studies.\n",
    "adnn.save_weights(\"my_model_init\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c16e3-5f49-4a22-b8b2-afb5163e3df2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Perform the training\n",
    "\n",
    "And now we start the training by calling the function `fit` with the appropriate parameters.\n",
    "\n",
    "What happens if you change the values of some hyperparameters and repeat the training? For example you can change the number of epochs with the `set_epochs(N)` method, or the learning rates of the classifier and adversary.\n",
    "\n",
    "Don't touch the $\\alpha$ parameter for now, we will see its impact later.\n",
    "\n",
    "**YOUR TURN: train the ADNN model. Try to repeat the training changing the default value of some parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af243aa-5a2b-4766-a4b2-1a90cf97e0c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74b51da-1c0e-4e97-bfcd-00275d78ad10",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# How do we quantify the ADNN performance\n",
    "\n",
    "Now that our model is trained we want to know how well it will perform on a test dataset that has not been used to train it. But we will look also at the training dataset itself to search for signs of overtraining.\n",
    "\n",
    "In the following we will look at several distributions and plots that will help us to quantify the ADNN performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91771967-c223-4c92-b798-f5813831600d",
   "metadata": {},
   "source": [
    "## Plot the probability distributions for the three output nodes of C\n",
    "\n",
    "First, we can look at the output distributions of the classifier. Remember that we have used a *softmax* activation function for the last layer, therefore the 3 outputs are forced to sum to unity and can be interpreted as probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6751c8-6356-449e-ab2c-a1578a06471b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_predict_train = adnn.predict_proba(X)\n",
    "Y_predict_val = adnn.predict_proba(X_val)\n",
    "\n",
    "axis = np.linspace(0,1,20)\n",
    "\n",
    "plt.hist(Y_predict_train[:,0].numpy(), bins = axis, label = 'VBF class - training',  histtype='step', color='r',  density=True, linewidth=2 )\n",
    "plt.hist(Y_predict_train[:,1].numpy(), bins = axis, label = 'ggH class - training',  histtype='step', color='g',  density=True, linewidth=2 )\n",
    "plt.hist(Y_predict_train[:,2].numpy(), bins = axis, label = 'BKG class - training',  histtype='step', color='b',  density=True, linewidth=2 )\n",
    "plt.hist(Y_predict_val[:,0].numpy(), bins = axis, label = 'VBF class - validation',  histtype='step', color='r',  density=True, linewidth=2, linestyle=\"dashed\" )\n",
    "plt.hist(Y_predict_val[:,1].numpy(), bins = axis, label = 'ggH class - validation',  histtype='step', color='g',  density=True, linewidth=2, linestyle=\"dashed\" )\n",
    "plt.hist(Y_predict_val[:,2].numpy(), bins = axis, label = 'BKG class - validation',  histtype='step', color='b',  density=True, linewidth=2, linestyle=\"dashed\" )\n",
    "\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.legend(frameon=False, bbox_to_anchor=(1.05, 1.))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d948701c-79f6-4336-9129-7999b5dc4f1b",
   "metadata": {},
   "source": [
    "## Plot the probability distributions for labelled events\n",
    "\n",
    "We can now look at the probability distributions of the 3 output nodes using the known labels (`isVBF`, `isGGH`, `isBKG`) of our events.\n",
    "\n",
    "**YOUR TURN: make the plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548cf63-6098-4d0c-b36e-7d992cfa2768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "### HINT: you can use the following sintax\n",
    "### adnn.predict_proba( df_val[ df_val['isVBF']==1 ].values[:,0:NDIM] )[:,0]\n",
    "###                                      ^                    ^           ^\n",
    "###                                      |                    |           |\n",
    "###                                select VBF events          |           |\n",
    "###                                               get the input features  |\n",
    "###                                                             select the VBF output node (i.e. node 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eda42ea-9945-4292-ba2f-64be8351f6fd",
   "metadata": {},
   "source": [
    "## Plot the probability distributions of different VBF signal models\n",
    "\n",
    "If the output of the ADNN was model independent, we would expect to see statistically consistent distributions for the different VBF models. Let's then compare the VBF output node distributions for all our models.\n",
    "\n",
    "**YOUR TURN: make the same plots as above, but this time for the `isSM`, `isBMS0`, ...,`isBSM5` labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6900f951-0f7f-4eaa-b2ce-adfbc54a0b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_model_dists():\n",
    "    ### YOUR CODE HERE\n",
    "    ### it's useful to embed this plots in a function, as we will reuse them later quite often\n",
    "\n",
    "plot_model_dists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e483a388-649e-4685-b444-2354310176aa",
   "metadata": {},
   "source": [
    "## Plot the confusion matrices\n",
    "\n",
    "Confusion matrices are useful tools to check in a visual way the classification power of our network. The following helper function can be used to make some nice plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1592234-d255-406a-ae1a-78958bb676e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "#from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize = 16)\n",
    "    plt.yticks(tick_marks, classes, fontsize = 16)\n",
    "\n",
    "    thresh = cm.max() / 1.2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",fontsize=10)\n",
    "\n",
    "    plt.xlabel(\"Predicted label\", fontsize=16)\n",
    "    plt.ylabel(\"True label\", fontsize=16)\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318e8bb-d7a7-41a2-a1d8-8757aa0570ee",
   "metadata": {},
   "source": [
    "We want to plot the classifier response matrix first.\n",
    "\n",
    "**YOUR TURN: plot the classifier confusion matrix using the validation dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2b3ad1-0e90-442c-8420-615a5313e6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y_pred_for_cm = adnn.predict_proba(X_val)\n",
    "\n",
    "# Note the argmax function below, why do we need it?\n",
    "Y_true_max = np.argmax(Y_val, axis=1)\n",
    "Y_pred_max = np.argmax(Y_pred_for_cm, axis=1)\n",
    "\n",
    "print('Confusion Matrix Classifier')\n",
    "C = ### YOUR CODE HERE\n",
    "### HINT: the easiest way is to use the confusion_matrix method we imported from sklearn.metrics\n",
    "C = np.around(C, decimals=3)\n",
    "print(C)\n",
    "\n",
    "print('Classification Report')\n",
    "target_names = ['VBF','ggH','BKG']\n",
    "print(classification_report(Y_true_max, Y_pred_max, target_names=target_names))\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(C, classes=target_names, title='')\n",
    "plt.savefig('cm.pdf', dpi='figure', bbox_inches='tight',transparent=True)\n",
    "\n",
    "plt.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399633e-2c77-4018-b826-9df7bf3ecfc1",
   "metadata": {},
   "source": [
    "**YOUR TURN: Let's now plot the confusion matrix of the adversary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe66fa6-39cf-450c-8ef8-30f24d16209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a subset of the validation dataset containing only VBF (SM or BSM) events\n",
    "X_val_for_cm = df_val[df_val[\"isVBF\"]==1].values[:,0:NDIM]\n",
    "Y_true_for_cm_adv = df_val[df_val[\"isVBF\"]==1].values[:,NDIM+3:NDIM+10]\n",
    "Y_pred_for_cm_adv = adnn.predict_proba_adv(X_val_for_cm)\n",
    "\n",
    "### YOUR CODE HERE\n",
    "### HINT: calculate the confusion matrix of the adversary using the same strategy as for the classifier\n",
    "\n",
    "C2 = np.around(C2, decimals=2)\n",
    "\n",
    "## The one below is an alternative way to compute the confusion matrix by hand\n",
    "## summing the predicted values in each matrix cell for all the events and \n",
    "## dividing by the sum of the values of a given row.\n",
    "\n",
    "# C2 = np.ndarray(shape=(tf.shape(Y_pred_for_cm_adv)[1].numpy(), tf.shape(Y_pred_for_cm_adv)[1].numpy()))\n",
    "\n",
    "# for ev in range(tf.shape(Y_pred_for_cm_adv)[0].numpy()):\n",
    "#     for pred_label in range(C2.shape[1]):\n",
    "#         C2[pred_label,Y_true_max_adv[ev]] += Y_pred_for_cm_adv[pred_label,Y_true_max_adv[ev]]\n",
    "\n",
    "# C2 = np.around( C2/C2.sum(axis=1)[:,None],decimals=2)\n",
    "\n",
    "target_names = ['model'+str(i) for i in range(7)]\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(C2, classes=target_names, title='')\n",
    "plt.savefig('cm.pdf', dpi='figure', bbox_inches='tight',transparent=True)\n",
    "\n",
    "plt.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37648d13-0316-477c-9913-29d128a53a7b",
   "metadata": {},
   "source": [
    "**YOUR TURN: a question now, how does the adversary confusion matrix look like? Can you explain why it is like that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203e01b-5f27-4d09-8545-86b4ef34c076",
   "metadata": {},
   "source": [
    "## Quantitative metrics to evaluate the ADNN performance\n",
    "\n",
    "Confusion matrices are nice looking, but let's now identify some possible quantitative metrics to assess the ADNN performance that can also be used later during the optimization.\n",
    "\n",
    "In particular we will see the *categorical accuracy* score as a metric to quantify the overall classification performance, and two alternatives to evaluate the performance of the adversary.\n",
    "\n",
    "In particular we can investigate two statistical tests:\n",
    "- the 2-sample Kolmogorov-Smirnov test;\n",
    "- the k-sample Anderson-Darling test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e1d190-643b-4f38-9f81-5da7410f4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import ks_2samp, anderson_ksamp\n",
    "\n",
    "# The classifier categorical accuracy is a good and simple metrics to evaluate the overall classification performance\n",
    "print(\"Classifier categorical accuracy = \", accuracy_score(Y_true_max, Y_pred_max))\n",
    "# We don't care about the adversary accuracy actually... but still here it is\n",
    "print(\"Adversary categorical accuracy = \", accuracy_score(Y_true_max_adv, Y_pred_max_adv))\n",
    "\n",
    "# But how do we evaluate the performance of the adversary? \n",
    "# Remember that we want the classifier output distribution to be ~ the same for different signal models.\n",
    "# Let's try to compute a 2-sample Kolmogorov-Smirnov test on each pair of different models.\n",
    "# The larger (smaller) is the p-value (test statistic) the higher is the compatibility between the distributions.\n",
    "preds = {}\n",
    "preds['isSM'] = adnn.predict_proba( df_val[ df_val['isSM']==1 ].values[:,0:NDIM] )[:,0]\n",
    "for i in range(6):\n",
    "    preds['isBSM'+str(i)] = adnn.predict_proba( df_val[ df_val['isBSM'+str(i)]==1 ].values[:,0:NDIM] )[:,0]\n",
    "    \n",
    "for i in range(7):\n",
    "    for j in range(i,6):\n",
    "        label1 = 'isSM' if i==0 else 'isBSM'+str(i-1)\n",
    "        label2 = 'isBSM'+str(j)\n",
    "        print ( \"KS between %s and %s --> \" %(label1,label2),ks_2samp(preds[label1],preds[label2]) )\n",
    "\n",
    "# An interesting alternative is the k-sample Anderson-Darling test.\n",
    "# It tests the null hypothesis that k-samples are drawn from the same population without having to specify the distribution function of that population. \n",
    "samples_for_ad = np.array( (preds['isSM'].numpy(), preds['isBSM0'].numpy(), preds['isBSM1'].numpy(), \n",
    "                         preds['isBSM2'].numpy(), preds['isBSM3'].numpy(), preds['isBSM4'].numpy(),\n",
    "                         preds['isBSM5'].numpy()) ).T\n",
    "\n",
    "ad_stat, _, _ = anderson_ksamp(samples_for_ad)\n",
    "print(ad_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72033b8e-86dd-466f-9f5d-2e769e7b92ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Check the impact of the $\\alpha$ hyperparameter\n",
    "\n",
    "As you may have realized, the $\\alpha$ parameter has a fundamental role in this procedure and has to be tuned with care in order to achieve the desired behavior.\n",
    "Let's see what happens if we set $\\alpha$ by hand to some arbitrary values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db4668-769d-4136-8306-f442b85b61a3",
   "metadata": {},
   "source": [
    "## $\\alpha = 0$ - no domain adaptation\n",
    "\n",
    "The first case we may want to study is when $\\alpha = 0$. This situation is essentially the same as dropping the adversary term, given that the adversary loss has no impact (it is multiplied by 0) on the overall loss.\n",
    "\n",
    "But note that some level of domain adaptation is still there, given that we are training our network on a dataset that is composed of different VBF signal models in equal proportions.\n",
    "\n",
    "To avoid any bias in the training procedure, we reset the optimizers initial state with the `reset_optimizers()` helper function, as well as the initial values of the model weights (`load_weights(\"my_model_init\")`).\n",
    "\n",
    "**YOUR TURN: train the ADNN setting $\\alpha=0$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01389cb-d531-4997-917a-a4657c9201cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb518612-99dd-4ebb-ab33-32f82db62e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model weights of this configuration\n",
    "adnn.save_weights(\"my_model_alpha0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a988f387-2ce8-4c09-b3a5-91cf9c6a144a",
   "metadata": {},
   "source": [
    "**YOUR TURN: now you can check the metrics we have seen before (for example the classifier categorical accuracy and the K-S test statistics) and plot the VBF output distributions for all the models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb376e7f-1237-4e46-a765-14854c02f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d20c557-4c38-4fe7-b334-376108048cba",
   "metadata": {},
   "source": [
    "## $\\alpha = 0.01$ - let's start increasing gradually the adversary importance\n",
    "\n",
    "**YOUR TURN: repeat the previous study but this time setting $\\alpha=0.01$. What are the differences?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d820a8bb-5265-441e-af84-92d6a02736af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c3bb3d-d060-4b1a-a1d0-f2938022ed8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## $\\alpha = 0.1$ - let's start increasing gradually the adversary importance\n",
    "\n",
    "**YOUR TURN: repeat the previous study but this time setting $\\alpha=0.1$. What are the differences?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc87f22-7176-4493-aaf0-7a1b2663dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b124f6-6a24-4719-b885-ea1e36dc0b67",
   "metadata": {},
   "source": [
    "## $\\alpha = 1$ - let's start increasing gradually the adversary importance\n",
    "\n",
    "**YOUR TURN: repeat the previous study but this time setting $\\alpha=1$. What are the differences?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f975121-0ce3-4f84-8344-e6dfe529da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b0da11-c73b-4b8a-96ec-5b76e8787ebf",
   "metadata": {},
   "source": [
    "## $\\alpha = 100$ - let's start increasing gradually the adversary importance\n",
    "\n",
    "**YOUR TURN: repeat the previous study but this time setting $\\alpha=100$. What are the differences?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402ed46-1dd3-4ff0-88e4-8ea5b48ee337",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e461b24-fbd3-40a7-9543-81fe92b381ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Tradeoff between accuracy and model dependence... How do we find a sweet spot?\n",
    "\n",
    "We have seen that the choice of $\\alpha$ is extremely important. The best value is a tradeoff between the accuracy of the classifier and the amount of model dependence.\n",
    "\n",
    "We can use the **Optuna** tool to find a sweet spot according to the metrics we have seen previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579e7f2-5754-4d3c-a975-87be6033e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340a1688-336b-4be7-afbb-d06984076db4",
   "metadata": {},
   "source": [
    "We have to define a function `evaluate_performance(trial)` that does the following:\n",
    "\n",
    "- resets the ADNN optimizers, loads the initial weights, suggests an $\\alpha$ value and trains the ADNN;\n",
    "- returns the K-S test statistics and the classifier categorical accuracy.\n",
    "\n",
    "Note: Optuna makes use of various sampling strategies to suggest the hyperparameter values at each trial. The default one is a Bayesian optimization algorithm called TPE. More details can be found in the Optuna [documentation](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.BaseSampler.html).\n",
    "\n",
    "**YOUR TURN: use the template function below to implement these functionalities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd6720d-237b-4bcc-a06c-898f72bda981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def evaluate_performance (trial) :\n",
    "     # For each trial (i.e. each call of this function), suggests a float value for alpha in the defined range\n",
    "    alpha = trial.suggest_float ('alpha', 0.1, 100)\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    return ks_test_stat, ca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2d0098-b9ec-43fb-87d1-d8b72843b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following is needed to start the optimization\n",
    "# Note that we specify 2 \"directions\" corresponding to whether we want to minimize or maximize the objectives\n",
    "# In this case we simultaneously minimize the K-S test statistics and maximize the categorical accuracy\n",
    "study = optuna.create_study(directions=['minimize', 'maximize'])\n",
    "# Define the number of trials\n",
    "study.optimize(evaluate_performance,n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eaacef-72e1-4ff5-9ec4-87530f2593df",
   "metadata": {},
   "source": [
    "Once the optimization is over, we can produce a nice [Pareto front plot](https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_pareto_front.html) and extract a dataframe containing the best trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cafdc1-aab9-40ca-a014-164201f3ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.matplotlib.plot_pareto_front(study, target_names=[\"Average K-S test\", \"Accuracy\"])\n",
    "\n",
    "plt.title(\" \")\n",
    "plt.xlabel(\"Average K-S test\", fontsize=12)\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.legend(prop={'size': 12},frameon=False)\n",
    "plt.show()\n",
    "\n",
    "opt_df = study.trials_dataframe()\n",
    "\n",
    "for best_trial in study.best_trials:\n",
    "    \n",
    "    print (opt_df[opt_df[\"number\"]==best_trial.number][['values_0','values_1','params_alpha']])\n",
    "    \n",
    "# Reset matplotlib default style that gets overwritten by optuna\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b354b4-52e6-4ec8-b260-7b2a2d6bdb61",
   "metadata": {},
   "source": [
    "## Let's pick the $\\alpha$ value corresponding to the best trial with the lowest mean K-S and train again\n",
    "\n",
    "**YOUR TURN: now you should be expert enough to do this with your eyes closed :). You can also consider to increase the number of epochs for this final training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19657f2-ba50-4ac4-a461-7286329c07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f71d64-fe48-46b6-85d5-ae9e5ac6af80",
   "metadata": {},
   "source": [
    "**YOUR TURN: And now check again the metrics we have seen before (for example the classifier categorical accuracy and the K-S test statistics) and plot the VBF output distributions for all the models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09b21f-8c4f-4a2d-8901-75729ccac2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c297e36-0cba-4fef-8214-04510775c642",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Summary\n",
    "\n",
    "Let's finish summarizing the results. Perhaps you didn't realize, but we have actually analyzed two cases of Domain Adaptation:\n",
    "\n",
    "1. a full-fledged Domain Adversarial Deep Neural Network;\n",
    "2. a simpler approach in which we set $\\alpha=0$. Note that this is still a Domain Adaptation approach (even without the adversarial term), because we trained the model on a dataset that contains events from both the source domain (SM VBF) and the target domain (BSM VBF). Also, note that in typical HEP applications the model is trained using only SM events.\n",
    "3. Wait... but we haven't checked what happens in the typical application. As an excercise, let's train a simple DNN with the typical approach and compare with the previous two.\n",
    "\n",
    "Let's run approach 3 in a separate [notebook](./Excercise_DA_MLhackathon_SimpleDNN_ForStudents.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a39c1-f122-4bf6-a621-c855da66adaf",
   "metadata": {},
   "source": [
    "The `summary()` function below will output several useful information:\n",
    "- the average K-S test statistic;\n",
    "- the classifier categorical accuracy for the mixture of SM and BSM signal events;\n",
    "- the classifier categorical accuracy for each of the 7 signal models;\n",
    "- the confusion matrix of each model separately (note that the ones seen before corresponded to the SM-BSM mixture)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de10e00-c75c-40aa-9efe-fe254c35c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary():\n",
    "    preds = {}\n",
    "    preds['isSM'] = adnn.predict_proba( df_val[ df_val['isSM']==1 ].values[:,0:NDIM] )[:,0]\n",
    "    for i in range(6):\n",
    "        preds['isBSM'+str(i)] = adnn.predict_proba( df_val[ df_val['isBSM'+str(i)]==1 ].values[:,0:NDIM] )[:,0]\n",
    "\n",
    "    ks_test_stat = 0\n",
    "    comb=0\n",
    "    for i in range(7):\n",
    "        for j in range(i,6):\n",
    "            label1 = 'isSM' if i==0 else 'isBSM'+str(i-1)\n",
    "            label2 = 'isBSM'+str(j)\n",
    "            stat, pval = ks_2samp(preds[label1],preds[label2])\n",
    "            ks_test_stat += stat\n",
    "            comb+=1\n",
    "    ks_test_stat = ks_test_stat/comb\n",
    "    print(\"Average K-S test stat = \", ks_test_stat)\n",
    "\n",
    "    X      = df_val.values[:,0:NDIM]\n",
    "    Y_true = df_val.values[:,NDIM:NDIM+3]\n",
    "\n",
    "    Y_pred = adnn.predict_proba(X)\n",
    "\n",
    "    Y_true_max = np.argmax(Y_true, axis=1)\n",
    "    Y_pred_max = np.argmax(Y_pred, axis=1)\n",
    "    print(\"Classifier categorical accuracy for SM-BSM model mixture = %s\" %(accuracy_score(Y_true_max, Y_pred_max)))\n",
    "\n",
    "    #And now the categorical accuracy for each of the 7 models separately\n",
    "    for i in range(7):\n",
    "        label = 'isSM' if i==0 else 'isBSM'+str(i-1)\n",
    "        X      = df_val[ (df_val[label]==1) | (df_val['isBKG']==1) | (df_val['isGGH']==1) ].values[:,0:NDIM]\n",
    "        Y_true = df_val[ (df_val[label]==1) | (df_val['isBKG']==1) | (df_val['isGGH']==1) ].values[:,NDIM:NDIM+3]\n",
    "\n",
    "        Y_pred = adnn.predict_proba(X)\n",
    "\n",
    "        Y_true_max = np.argmax(Y_true, axis=1)\n",
    "        Y_pred_max = np.argmax(Y_pred, axis=1)\n",
    "        print(\"Classifier categorical accuracy for model %s = %s\" %(label, accuracy_score(Y_true_max, Y_pred_max)))\n",
    "\n",
    "        C = confusion_matrix(Y_true_max, Y_pred_max, normalize=\"true\")\n",
    "        C = np.around(C, decimals=3)\n",
    "        print(\"Fraction of %s events classified as VBF = %s\" %(label, C[0,0]))\n",
    " \n",
    "        target_names = [label,'ggH','BKG']\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(C, classes=target_names, title='')\n",
    "        plt.show(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761e0c1-c6d4-44c6-a47a-a2df473c8e4b",
   "metadata": {},
   "source": [
    "**YOUR TURN: load the ADNN weights (`adnn.load_weights(model_name)`) corresponding to the final configuration (approach 1) and to the $\\alpha=0$ case (approach 2). Run the `summary()` function and compare the results. Compare also with the results obtained in the other notebook, corresponding to approach 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a1d2c-ff5b-4de4-83d7-a4b4afe13e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afd8431-123c-4912-9623-8ddffe0e414e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b9730-a871-4e99-ac9c-127a8cd57610",
   "metadata": {},
   "source": [
    "In summary, comparing the 3 approaches we have seen that:\n",
    "\n",
    "1. The ADNN performance is characterized by a low average K-S test statistic and uniform categorical accuracies for all the models.\n",
    "2. The ADNN with $\\alpha=0$ seems to perform better if we only look at the categorical accuracies, but the average KS is fairly high and if we look at the confusion matrices in detail we can observe that there is a large variation in the fraction of signal events classified as VBF depending on the signal model.\n",
    "3. The simple DNN has a fairly high accuracy if evaluated for SM events (i.e. target domain equal to the source domain), but starts to fail dramatically as soon as we evaluate it on one of the BSM models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49b07c-b0b2-4808-a57d-5090ec9a99d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# References\n",
    "\n",
    "- Camaiani B. et al., *Model independent measurements of standard model cross sections with domain adaptation*, EPJ C 82 921 (2022), [doi:10.1140/epjc/s10052-022-10871-3](https://doi.org/10.1140/epjc/s10052-022-10871-3)\n",
    "- Ben-David S., Blitzer J., Crammer K. et al. *A theory of learning from different domains*. Mach. Learn. 79, 151175 (2010). https://doi.org/10.1007/s10994-009-5152-4\n",
    "- Louppe G., Kagan M., Cranmer K. *Learning to Pivot with Adversarial Networks*, [arXiv:1611.01046](https://arxiv.org/abs/1611.01046)\n",
    "- Y. Ganin et al. *Domain-adversarial training of neural networks*. J. Mach. Learn. Res. 17, 20302096 (2016). [arXiv:1505.07818](https://arxiv.org/abs/1505.07818)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8fbe6-b8e4-495d-be17-5619a6de0f37",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# BACKUP (Additional studies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6371be25-3bc6-4b20-946b-4acb07a09dbe",
   "metadata": {},
   "source": [
    "## Optimize other hyperparameters\n",
    "\n",
    "Optuna is a very powerful tool for hyperparameter optimization. In fact we can also optimize more hyperparameters simultaneously.\n",
    "\n",
    "Similarly to what we have done with $\\alpha$, let's try to optimize also something else, such as the number of layers in C and A, the number of nodes, or the learning rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd3c8f-fee9-4261-b3fb-92f6c08084cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Optimize using the AD test\n",
    "\n",
    "Repeat the optimization using the k-sample Anderson-Darling test instead of K-S."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889f419b-45ba-4ced-b461-edf58f920257",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Agnosticism against unseen physics models\n",
    "\n",
    "We may argue that the signal model chosen by Nature is unknown and in general different from the ones the discriminator has been trained on. This is indeed the primary reason why one wants the discriminator performance to be model independent in the first place. It is thus important to establish a procedure to evaluate the degree of model independence of the discriminator with respect to signal models unseen in the training.\n",
    "\n",
    "In this specific use case, we want to check the performance of the *ADNN* for a given model that was not seen in the training. For achieving this goal, let's retrain the *ADNN* dropping one model (say `isBSM5`) from the dataset.\n",
    "\n",
    "**NB** The results of this test are peculiar of the particular physics models taken into account."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
